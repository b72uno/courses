{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEEK 1\n",
    "\n",
    "Q: What to start with in ML? \n",
    "A: Unsupervised learning and generative algorithms\n",
    "\n",
    "Architecture engineering is the new feature engineering\n",
    "\n",
    "Three ML types - Supervised, Unsupervised and Reinforcement. Think chess game - Supervised gives feedback every move, unsupervised does nothing even if game won, reinforcement gives feedback only upon winning the game.\n",
    "Watch out for outliers!\n",
    "\n",
    "**Know and understand the gradient descent like the back of your hand. It is everywhere in ML!**\n",
    "\n",
    "Linear regression model + activation function = stuff. Sigmoid function sigmoid(x) = 1/(1+e^-x)\n",
    "There are logistic (sigmoid), tanh and softmax (WAT?) functions used as activation functions.\n",
    "\n",
    "A common metric for how wrong the predictions are (the error) is the sum of squared errors.\n",
    "#TODO: LATEX THIS THING, ok?  See Gradient Descent in Intro to Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEEK 2\n",
    "\n",
    "Thou shalt never use your testing data for training! gandarf.jpg\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
