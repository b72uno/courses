{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An algorithm is either unsupervised or supervised and it is either parametric or non-parametric. Parametricism is about the way the learning is **stored** and often by extension, the **method for learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A paramteric model is characterized by having a fixed number of parameters whereas a non-parametric model's number of parameters is infinite (determined by data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weight = 0.1\n",
    "\n",
    "def neural_network(input, weight):\n",
    "    prediction = input * weight\n",
    "    return prediction\n",
    "\n",
    "number_of_toes = [8.5, 9.5, 10, 9]\n",
    "input = number_of_toes[0]\n",
    "pred = neural_network(input, weight)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "#T his dataset is the current status at the beginning of each game for the first 4 games in a season.\n",
    "\n",
    "# toes = current number of toes\n",
    "# wlrec = current games won (percent)\n",
    "# nfans = fan count (in millions) \n",
    "\n",
    "toes = [8.5, 9.5, 9.9, 9.0]\n",
    "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
    "nfans = [1.2, 1.3, 0.5, 1.0] \n",
    "\n",
    "# input corresponds to every entry\n",
    "# for the first game of the season\n",
    "weights = [0.1, 0.2, 0]\n",
    "\n",
    "def neural_network(inputs, weights):\n",
    "    pred = w_sum(input, weights)\n",
    "    return pred\n",
    "\n",
    "def w_sum(a, b):\n",
    "    assert(len(a) == len(b))\n",
    "    output = 0\n",
    "    \n",
    "    for i in range(len(a)):\n",
    "        output += (a[i] * b[i])\n",
    "    \n",
    "    return output\n",
    "    \n",
    "\n",
    "input = [toes[0], wlrec[0], nfans[0]]\n",
    "pred = neural_network(input, weights)\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The intuition behind how and why a dot product (weighted sum) works is easily one of the most important parts of truly understanding how neural networks make predictions. Loosely stated, a dot product gives us __notion of similarity__ between two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n"
     ]
    }
   ],
   "source": [
    "# Same above code in Numpy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "weights = np.array([0.1, 0.2, 0])\n",
    "\n",
    "def neural_network(input, weights):\n",
    "    pred = input.dot(weights)\n",
    "\n",
    "    return pred\n",
    "\n",
    "toes = np.array([8.5, 9.5, 9.9, 9.0])\n",
    "wlrec = np.array([0.65, 0.8, 0.8, 0.9])\n",
    "nfans = np.array([1.2, 1.3, 0.5, 1.0])\n",
    "\n",
    "#input corresponds to every entry\n",
    "#for the first game of season\n",
    "                 \n",
    "input = np.array([toes[0], wlrec[0], nfans[0]])\n",
    "pred = neural_network(input, weights)\n",
    "print(pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.195, 0.13, 0.5850000000000001]\n"
     ]
    }
   ],
   "source": [
    "# single input to multiple outputs\n",
    "''' instead of predicting just whether the \n",
    "team won or lost now we're also predicting \n",
    "whether they are happy/sad AND the percentage\n",
    "of the team that is hurt. We are making this \n",
    "prediction using only the current\n",
    "win/loss record'''\n",
    "\n",
    "weights = [0.3, 0.2, 0.9]\n",
    "\n",
    "def neural_network(input, weights):\n",
    "    \n",
    "    pred = ele_mul(input, weights)\n",
    "    \n",
    "    return pred\n",
    "\n",
    "def ele_mul(number, vector):\n",
    "    output = [0, 0, 0]\n",
    "    assert(len(output) == len(vector))\n",
    "    \n",
    "    for i in range(len(vector)):\n",
    "        output[i] = number * vector[i]\n",
    "    \n",
    "    return output\n",
    "\n",
    "wlrec = [0.65, 0.65, 1.2]\n",
    "\n",
    "input = wlrec[0]\n",
    "\n",
    "pred = neural_network(input, weights)\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55500000000000005, 0.98000000000000009, 0.96500000000000008]\n"
     ]
    }
   ],
   "source": [
    "# Multiple inputs to multiple outputs\n",
    "#ntoes #%win #fans\n",
    "weights = [[0.1, 0.1, -0.3],# hurt?\n",
    "           [0.1, 0.2, 0.0], # win?\n",
    "           [0.0, 1.3, 0.1]] # sad?\n",
    "\n",
    "\n",
    "def neural_network(input, weights):\n",
    "    pred = vect_mat_mul(input, weights)\n",
    "    return pred\n",
    "\n",
    "def vect_mat_mul(vect, matrix):\n",
    "    a = vect\n",
    "    b = matrix\n",
    "    \n",
    "    assert(len(a) == len(b)\n",
    "           \n",
    "    # fixed \n",
    "    output = []\n",
    "    \n",
    "    for i in range(len(a))\n",
    "        # fixed \n",
    "        output.append(np.dot(a, b[i]))\n",
    "        \n",
    "    return output\n",
    "\n",
    "''' This dataset is the current status at\n",
    "the beginning of each game for the first 4\n",
    "games in a season\n",
    "\n",
    "toes = current number of toes\n",
    "wlrec = current games won (percent)\n",
    "nfans = fan count (in millions) '''\n",
    "\n",
    "toes = [8.5, 9.5, 9.9, 9.0]\n",
    "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "\n",
    "# input corresponds to every entry\n",
    "# for the first game of the season\n",
    "input = [toes[0], wlrec[0], nfans[0]]\n",
    "pred = neural_network(input, weights)\n",
    "print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.496  1.256 -0.286]\n"
     ]
    }
   ],
   "source": [
    "# Another hidden layer added\n",
    "in_wgt = np.array([[0.1, 0.2, -0.1],\n",
    "         [-0.1, 0.1, 0.9],\n",
    "         [0.1, 0.4, 0.1]])\n",
    "\n",
    "hp_wgt = np.array([[0.3, 1.1, -0.3],\n",
    "          [0.1, 0.2, 0.0],\n",
    "          [0.0, 1.3, 0.1]])\n",
    "\n",
    "weights = [in_wgt, hp_wgt]\n",
    "\n",
    "def neural_network(input, weights):\n",
    "    hid = input.dot(weights[0])\n",
    "    pred = hid.dot(weights[1])\n",
    "    return pred\n",
    "\n",
    "toes = np.array([8.5, 9.5, 9.9, 9.0])\n",
    "wlrec = np.array([0.65, 0.8, 0.8, 0.9])\n",
    "nfans = np.array([1.2, 1.3, 0.5, 1.0])\n",
    "\n",
    "input = np.array([toes[0], wlrec[0], nfans[0]])\n",
    "\n",
    "pred = neural_network(input, weights)\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.30250000000000005 Prediction: 0.25\n",
      "Error: 0.3019502500000001 Prediction: 0.2505\n",
      "Error: 0.30140100000000003 Prediction: 0.251\n",
      "Error: 0.30085225 Prediction: 0.2515\n",
      "Error: 0.30030400000000007 Prediction: 0.252\n",
      "Error: 0.2997562500000001 Prediction: 0.2525\n",
      "Error: 0.29920900000000006 Prediction: 0.253\n",
      "Error: 0.29866224999999996 Prediction: 0.2535\n",
      "Error: 0.29811600000000005 Prediction: 0.254\n",
      "Error: 0.2975702500000001 Prediction: 0.2545\n",
      "Error: 0.29702500000000004 Prediction: 0.255\n",
      "Error: 0.29648025 Prediction: 0.2555\n",
      "Error: 0.29593600000000003 Prediction: 0.256\n",
      "Error: 0.2953922500000001 Prediction: 0.2565\n",
      "Error: 0.294849 Prediction: 0.257\n",
      "Error: 0.29430625 Prediction: 0.2575\n",
      "Error: 0.293764 Prediction: 0.258\n",
      "Error: 0.2932222500000001 Prediction: 0.2585\n",
      "Error: 0.292681 Prediction: 0.259\n",
      "Error: 0.29214025 Prediction: 0.2595\n",
      "Error: 0.2916 Prediction: 0.26\n",
      "Error: 0.2910602500000001 Prediction: 0.2605\n",
      "Error: 0.29052100000000003 Prediction: 0.261\n",
      "Error: 0.28998225 Prediction: 0.2615\n",
      "Error: 0.28944400000000003 Prediction: 0.262\n",
      "Error: 0.2889062500000001 Prediction: 0.2625\n",
      "Error: 0.28836900000000004 Prediction: 0.263\n",
      "Error: 0.28783224999999996 Prediction: 0.2635\n",
      "Error: 0.28729600000000005 Prediction: 0.264\n",
      "Error: 0.2867602500000001 Prediction: 0.2645\n",
      "Error: 0.286225 Prediction: 0.265\n",
      "Error: 0.28569025 Prediction: 0.2655\n",
      "Error: 0.285156 Prediction: 0.266\n",
      "Error: 0.2846222500000001 Prediction: 0.2665\n",
      "Error: 0.28408900000000004 Prediction: 0.267\n",
      "Error: 0.28355624999999995 Prediction: 0.2675\n",
      "Error: 0.28302400000000005 Prediction: 0.268\n",
      "Error: 0.2824922500000001 Prediction: 0.2685\n",
      "Error: 0.281961 Prediction: 0.269\n",
      "Error: 0.28143025 Prediction: 0.2695\n",
      "Error: 0.28090000000000004 Prediction: 0.27\n",
      "Error: 0.2803702500000001 Prediction: 0.2705\n",
      "Error: 0.279841 Prediction: 0.271\n",
      "Error: 0.27931225 Prediction: 0.2715\n",
      "Error: 0.27878400000000003 Prediction: 0.272\n",
      "Error: 0.2782562500000001 Prediction: 0.2725\n",
      "Error: 0.277729 Prediction: 0.273\n",
      "Error: 0.27720225 Prediction: 0.2735\n",
      "Error: 0.27667600000000003 Prediction: 0.274\n",
      "Error: 0.2761502500000001 Prediction: 0.2745\n",
      "Error: 0.275625 Prediction: 0.275\n",
      "Error: 0.27510025 Prediction: 0.2755\n",
      "Error: 0.27457600000000004 Prediction: 0.276\n",
      "Error: 0.27405225000000005 Prediction: 0.2765\n",
      "Error: 0.273529 Prediction: 0.277\n",
      "Error: 0.27300624999999995 Prediction: 0.2775\n",
      "Error: 0.272484 Prediction: 0.278\n",
      "Error: 0.27196225000000007 Prediction: 0.2785\n",
      "Error: 0.27144100000000004 Prediction: 0.279\n",
      "Error: 0.27092025 Prediction: 0.2795\n",
      "Error: 0.27040000000000003 Prediction: 0.28\n",
      "Error: 0.2698802500000001 Prediction: 0.2805\n",
      "Error: 0.269361 Prediction: 0.281\n",
      "Error: 0.26884224999999995 Prediction: 0.28150000000000003\n",
      "Error: 0.268324 Prediction: 0.28200000000000003\n",
      "Error: 0.2678062500000001 Prediction: 0.28250000000000003\n",
      "Error: 0.267289 Prediction: 0.28300000000000003\n",
      "Error: 0.26677224999999993 Prediction: 0.28350000000000003\n",
      "Error: 0.266256 Prediction: 0.28400000000000003\n",
      "Error: 0.26574025000000007 Prediction: 0.28450000000000003\n",
      "Error: 0.265225 Prediction: 0.28500000000000003\n",
      "Error: 0.26471025 Prediction: 0.28550000000000003\n",
      "Error: 0.264196 Prediction: 0.28600000000000003\n",
      "Error: 0.26368225000000006 Prediction: 0.28650000000000003\n",
      "Error: 0.263169 Prediction: 0.28700000000000003\n",
      "Error: 0.26265625 Prediction: 0.28750000000000003\n",
      "Error: 0.262144 Prediction: 0.28800000000000003\n",
      "Error: 0.26163225000000007 Prediction: 0.28850000000000003\n",
      "Error: 0.261121 Prediction: 0.28900000000000003\n",
      "Error: 0.26061024999999993 Prediction: 0.28950000000000004\n",
      "Error: 0.2601 Prediction: 0.29000000000000004\n",
      "Error: 0.2595902500000001 Prediction: 0.29050000000000004\n",
      "Error: 0.259081 Prediction: 0.29100000000000004\n",
      "Error: 0.25857224999999995 Prediction: 0.29150000000000004\n",
      "Error: 0.258064 Prediction: 0.29200000000000004\n",
      "Error: 0.25755625000000004 Prediction: 0.29250000000000004\n",
      "Error: 0.257049 Prediction: 0.29300000000000004\n",
      "Error: 0.25654224999999997 Prediction: 0.29350000000000004\n",
      "Error: 0.256036 Prediction: 0.29400000000000004\n",
      "Error: 0.25553025000000007 Prediction: 0.29450000000000004\n",
      "Error: 0.255025 Prediction: 0.29500000000000004\n",
      "Error: 0.25452024999999995 Prediction: 0.29550000000000004\n",
      "Error: 0.254016 Prediction: 0.29600000000000004\n",
      "Error: 0.25351225000000005 Prediction: 0.29650000000000004\n",
      "Error: 0.253009 Prediction: 0.29700000000000004\n",
      "Error: 0.25250624999999993 Prediction: 0.29750000000000004\n",
      "Error: 0.252004 Prediction: 0.29800000000000004\n",
      "Error: 0.25150225000000004 Prediction: 0.29850000000000004\n",
      "Error: 0.251001 Prediction: 0.29900000000000004\n",
      "Error: 0.2505002499999999 Prediction: 0.29950000000000004\n",
      "Error: 0.25 Prediction: 0.30000000000000004\n",
      "Error: 0.24950025 Prediction: 0.30050000000000004\n",
      "Error: 0.249001 Prediction: 0.30100000000000005\n",
      "Error: 0.24850225 Prediction: 0.30150000000000005\n",
      "Error: 0.248004 Prediction: 0.30200000000000005\n",
      "Error: 0.24750625 Prediction: 0.30250000000000005\n",
      "Error: 0.247009 Prediction: 0.30300000000000005\n",
      "Error: 0.24651225 Prediction: 0.30350000000000005\n",
      "Error: 0.24601599999999998 Prediction: 0.30400000000000005\n",
      "Error: 0.24552025 Prediction: 0.30450000000000005\n",
      "Error: 0.245025 Prediction: 0.30500000000000005\n",
      "Error: 0.24453025 Prediction: 0.30550000000000005\n",
      "Error: 0.244036 Prediction: 0.30600000000000005\n",
      "Error: 0.24354225 Prediction: 0.30650000000000005\n",
      "Error: 0.243049 Prediction: 0.30700000000000005\n",
      "Error: 0.24255625 Prediction: 0.30750000000000005\n",
      "Error: 0.242064 Prediction: 0.30800000000000005\n",
      "Error: 0.24157225 Prediction: 0.30850000000000005\n",
      "Error: 0.241081 Prediction: 0.30900000000000005\n",
      "Error: 0.24059025 Prediction: 0.30950000000000005\n",
      "Error: 0.24009999999999998 Prediction: 0.31000000000000005\n",
      "Error: 0.23961025 Prediction: 0.31050000000000005\n",
      "Error: 0.239121 Prediction: 0.31100000000000005\n",
      "Error: 0.23863225 Prediction: 0.31150000000000005\n",
      "Error: 0.238144 Prediction: 0.31200000000000006\n",
      "Error: 0.23765624999999999 Prediction: 0.31250000000000006\n",
      "Error: 0.237169 Prediction: 0.31300000000000006\n",
      "Error: 0.23668224999999998 Prediction: 0.31350000000000006\n",
      "Error: 0.236196 Prediction: 0.31400000000000006\n",
      "Error: 0.23571024999999998 Prediction: 0.31450000000000006\n",
      "Error: 0.235225 Prediction: 0.31500000000000006\n",
      "Error: 0.23474024999999998 Prediction: 0.31550000000000006\n",
      "Error: 0.234256 Prediction: 0.31600000000000006\n",
      "Error: 0.23377225 Prediction: 0.31650000000000006\n",
      "Error: 0.233289 Prediction: 0.31700000000000006\n",
      "Error: 0.23280625 Prediction: 0.31750000000000006\n",
      "Error: 0.23232399999999997 Prediction: 0.31800000000000006\n",
      "Error: 0.23184224999999997 Prediction: 0.31850000000000006\n",
      "Error: 0.23136099999999998 Prediction: 0.31900000000000006\n",
      "Error: 0.23088024999999998 Prediction: 0.31950000000000006\n",
      "Error: 0.2304 Prediction: 0.32000000000000006\n",
      "Error: 0.22992025 Prediction: 0.32050000000000006\n",
      "Error: 0.22944099999999998 Prediction: 0.32100000000000006\n",
      "Error: 0.22896224999999998 Prediction: 0.32150000000000006\n",
      "Error: 0.228484 Prediction: 0.32200000000000006\n",
      "Error: 0.22800625 Prediction: 0.32250000000000006\n",
      "Error: 0.22752899999999998 Prediction: 0.32300000000000006\n",
      "Error: 0.22705224999999998 Prediction: 0.32350000000000007\n",
      "Error: 0.22657599999999997 Prediction: 0.32400000000000007\n",
      "Error: 0.22610024999999997 Prediction: 0.32450000000000007\n",
      "Error: 0.225625 Prediction: 0.32500000000000007\n",
      "Error: 0.22515024999999997 Prediction: 0.32550000000000007\n",
      "Error: 0.224676 Prediction: 0.32600000000000007\n",
      "Error: 0.22420224999999996 Prediction: 0.32650000000000007\n",
      "Error: 0.22372899999999998 Prediction: 0.32700000000000007\n",
      "Error: 0.22325625 Prediction: 0.32750000000000007\n",
      "Error: 0.22278399999999998 Prediction: 0.32800000000000007\n",
      "Error: 0.22231225 Prediction: 0.32850000000000007\n",
      "Error: 0.22184099999999998 Prediction: 0.32900000000000007\n",
      "Error: 0.22137024999999996 Prediction: 0.32950000000000007\n",
      "Error: 0.22089999999999999 Prediction: 0.33000000000000007\n",
      "Error: 0.22043024999999997 Prediction: 0.33050000000000007\n",
      "Error: 0.21996099999999996 Prediction: 0.33100000000000007\n",
      "Error: 0.21949224999999997 Prediction: 0.3315000000000001\n",
      "Error: 0.21902399999999997 Prediction: 0.3320000000000001\n",
      "Error: 0.21855624999999998 Prediction: 0.3325000000000001\n",
      "Error: 0.21808899999999998 Prediction: 0.3330000000000001\n",
      "Error: 0.21762224999999996 Prediction: 0.3335000000000001\n",
      "Error: 0.21715599999999996 Prediction: 0.3340000000000001\n",
      "Error: 0.21669024999999997 Prediction: 0.3345000000000001\n",
      "Error: 0.21622499999999997 Prediction: 0.3350000000000001\n",
      "Error: 0.21576024999999996 Prediction: 0.3355000000000001\n",
      "Error: 0.21529599999999996 Prediction: 0.3360000000000001\n",
      "Error: 0.21483224999999997 Prediction: 0.3365000000000001\n",
      "Error: 0.21436899999999998 Prediction: 0.3370000000000001\n",
      "Error: 0.21390624999999996 Prediction: 0.3375000000000001\n",
      "Error: 0.21344399999999997 Prediction: 0.3380000000000001\n",
      "Error: 0.21298224999999996 Prediction: 0.3385000000000001\n",
      "Error: 0.21252099999999996 Prediction: 0.3390000000000001\n",
      "Error: 0.21206024999999998 Prediction: 0.3395000000000001\n",
      "Error: 0.21159999999999995 Prediction: 0.3400000000000001\n",
      "Error: 0.21114024999999997 Prediction: 0.3405000000000001\n",
      "Error: 0.21068099999999998 Prediction: 0.3410000000000001\n",
      "Error: 0.21022224999999997 Prediction: 0.3415000000000001\n",
      "Error: 0.20976399999999998 Prediction: 0.3420000000000001\n",
      "Error: 0.20930624999999997 Prediction: 0.3425000000000001\n",
      "Error: 0.20884899999999995 Prediction: 0.3430000000000001\n",
      "Error: 0.20839224999999997 Prediction: 0.3435000000000001\n",
      "Error: 0.20793599999999995 Prediction: 0.3440000000000001\n",
      "Error: 0.20748024999999998 Prediction: 0.3445000000000001\n",
      "Error: 0.20702499999999996 Prediction: 0.3450000000000001\n",
      "Error: 0.20657024999999996 Prediction: 0.3455000000000001\n",
      "Error: 0.20611599999999997 Prediction: 0.3460000000000001\n",
      "Error: 0.20566224999999996 Prediction: 0.3465000000000001\n",
      "Error: 0.20520899999999997 Prediction: 0.3470000000000001\n",
      "Error: 0.20475624999999997 Prediction: 0.3475000000000001\n",
      "Error: 0.20430399999999996 Prediction: 0.3480000000000001\n",
      "Error: 0.20385224999999996 Prediction: 0.3485000000000001\n",
      "Error: 0.20340099999999997 Prediction: 0.3490000000000001\n",
      "Error: 0.20295024999999997 Prediction: 0.3495000000000001\n",
      "Error: 0.20249999999999996 Prediction: 0.3500000000000001\n",
      "Error: 0.20205024999999996 Prediction: 0.3505000000000001\n",
      "Error: 0.20160099999999995 Prediction: 0.3510000000000001\n",
      "Error: 0.20115224999999995 Prediction: 0.3515000000000001\n",
      "Error: 0.20070399999999997 Prediction: 0.3520000000000001\n",
      "Error: 0.20025624999999997 Prediction: 0.3525000000000001\n",
      "Error: 0.19980899999999996 Prediction: 0.3530000000000001\n",
      "Error: 0.19936224999999996 Prediction: 0.3535000000000001\n",
      "Error: 0.19891599999999995 Prediction: 0.3540000000000001\n",
      "Error: 0.19847024999999996 Prediction: 0.3545000000000001\n",
      "Error: 0.19802499999999995 Prediction: 0.3550000000000001\n",
      "Error: 0.19758024999999996 Prediction: 0.3555000000000001\n",
      "Error: 0.19713599999999995 Prediction: 0.3560000000000001\n",
      "Error: 0.19669224999999996 Prediction: 0.3565000000000001\n",
      "Error: 0.19624899999999995 Prediction: 0.3570000000000001\n",
      "Error: 0.19580624999999996 Prediction: 0.3575000000000001\n",
      "Error: 0.19536399999999995 Prediction: 0.3580000000000001\n",
      "Error: 0.19492224999999996 Prediction: 0.3585000000000001\n",
      "Error: 0.19448099999999996 Prediction: 0.3590000000000001\n",
      "Error: 0.19404024999999994 Prediction: 0.3595000000000001\n",
      "Error: 0.19359999999999997 Prediction: 0.3600000000000001\n",
      "Error: 0.19316024999999995 Prediction: 0.3605000000000001\n",
      "Error: 0.19272099999999995 Prediction: 0.3610000000000001\n",
      "Error: 0.19228224999999996 Prediction: 0.3615000000000001\n",
      "Error: 0.19184399999999996 Prediction: 0.3620000000000001\n",
      "Error: 0.19140624999999994 Prediction: 0.3625000000000001\n",
      "Error: 0.19096899999999994 Prediction: 0.3630000000000001\n",
      "Error: 0.19053224999999996 Prediction: 0.3635000000000001\n",
      "Error: 0.19009599999999996 Prediction: 0.3640000000000001\n",
      "Error: 0.18966024999999995 Prediction: 0.3645000000000001\n",
      "Error: 0.18922499999999995 Prediction: 0.3650000000000001\n",
      "Error: 0.18879024999999994 Prediction: 0.3655000000000001\n",
      "Error: 0.18835599999999994 Prediction: 0.3660000000000001\n",
      "Error: 0.18792224999999996 Prediction: 0.3665000000000001\n",
      "Error: 0.18748899999999996 Prediction: 0.3670000000000001\n",
      "Error: 0.18705624999999995 Prediction: 0.3675000000000001\n",
      "Error: 0.18662399999999996 Prediction: 0.3680000000000001\n",
      "Error: 0.18619224999999995 Prediction: 0.3685000000000001\n",
      "Error: 0.18576099999999995 Prediction: 0.3690000000000001\n",
      "Error: 0.18533024999999995 Prediction: 0.3695000000000001\n",
      "Error: 0.18489999999999995 Prediction: 0.3700000000000001\n",
      "Error: 0.18447024999999995 Prediction: 0.3705000000000001\n",
      "Error: 0.18404099999999995 Prediction: 0.3710000000000001\n",
      "Error: 0.18361224999999995 Prediction: 0.3715000000000001\n",
      "Error: 0.18318399999999996 Prediction: 0.3720000000000001\n",
      "Error: 0.18275624999999995 Prediction: 0.3725000000000001\n",
      "Error: 0.18232899999999994 Prediction: 0.3730000000000001\n",
      "Error: 0.18190224999999993 Prediction: 0.3735000000000001\n",
      "Error: 0.18147599999999994 Prediction: 0.3740000000000001\n",
      "Error: 0.18105024999999994 Prediction: 0.3745000000000001\n",
      "Error: 0.18062499999999995 Prediction: 0.3750000000000001\n",
      "Error: 0.18020024999999995 Prediction: 0.3755000000000001\n",
      "Error: 0.17977599999999994 Prediction: 0.3760000000000001\n",
      "Error: 0.17935224999999994 Prediction: 0.3765000000000001\n",
      "Error: 0.17892899999999995 Prediction: 0.3770000000000001\n",
      "Error: 0.17850624999999995 Prediction: 0.3775000000000001\n",
      "Error: 0.17808399999999994 Prediction: 0.3780000000000001\n",
      "Error: 0.17766224999999994 Prediction: 0.3785000000000001\n",
      "Error: 0.17724099999999995 Prediction: 0.3790000000000001\n",
      "Error: 0.17682024999999993 Prediction: 0.3795000000000001\n",
      "Error: 0.17639999999999995 Prediction: 0.3800000000000001\n",
      "Error: 0.17598024999999995 Prediction: 0.3805000000000001\n",
      "Error: 0.17556099999999994 Prediction: 0.3810000000000001\n",
      "Error: 0.17514224999999994 Prediction: 0.3815000000000001\n",
      "Error: 0.17472399999999993 Prediction: 0.3820000000000001\n",
      "Error: 0.17430624999999994 Prediction: 0.3825000000000001\n",
      "Error: 0.17388899999999993 Prediction: 0.3830000000000001\n",
      "Error: 0.17347224999999994 Prediction: 0.3835000000000001\n",
      "Error: 0.17305599999999993 Prediction: 0.3840000000000001\n",
      "Error: 0.17264024999999994 Prediction: 0.3845000000000001\n",
      "Error: 0.17222499999999993 Prediction: 0.3850000000000001\n",
      "Error: 0.17181024999999994 Prediction: 0.3855000000000001\n",
      "Error: 0.17139599999999994 Prediction: 0.3860000000000001\n",
      "Error: 0.17098224999999995 Prediction: 0.3865000000000001\n",
      "Error: 0.17056899999999994 Prediction: 0.3870000000000001\n",
      "Error: 0.17015624999999993 Prediction: 0.3875000000000001\n",
      "Error: 0.16974399999999992 Prediction: 0.3880000000000001\n",
      "Error: 0.16933224999999993 Prediction: 0.3885000000000001\n",
      "Error: 0.16892099999999993 Prediction: 0.3890000000000001\n",
      "Error: 0.16851024999999994 Prediction: 0.3895000000000001\n",
      "Error: 0.16809999999999994 Prediction: 0.3900000000000001\n",
      "Error: 0.16769024999999993 Prediction: 0.3905000000000001\n",
      "Error: 0.16728099999999993 Prediction: 0.3910000000000001\n",
      "Error: 0.16687224999999994 Prediction: 0.3915000000000001\n",
      "Error: 0.16646399999999995 Prediction: 0.3920000000000001\n",
      "Error: 0.16605624999999993 Prediction: 0.3925000000000001\n",
      "Error: 0.16564899999999994 Prediction: 0.3930000000000001\n",
      "Error: 0.16524224999999992 Prediction: 0.3935000000000001\n",
      "Error: 0.16483599999999993 Prediction: 0.39400000000000013\n",
      "Error: 0.16443024999999994 Prediction: 0.39450000000000013\n",
      "Error: 0.16402499999999992 Prediction: 0.39500000000000013\n",
      "Error: 0.16362024999999994 Prediction: 0.39550000000000013\n",
      "Error: 0.16321599999999994 Prediction: 0.39600000000000013\n",
      "Error: 0.16281224999999994 Prediction: 0.39650000000000013\n",
      "Error: 0.16240899999999994 Prediction: 0.39700000000000013\n",
      "Error: 0.16200624999999994 Prediction: 0.39750000000000013\n",
      "Error: 0.16160399999999994 Prediction: 0.39800000000000013\n",
      "Error: 0.16120224999999994 Prediction: 0.39850000000000013\n",
      "Error: 0.16080099999999992 Prediction: 0.39900000000000013\n",
      "Error: 0.16040024999999994 Prediction: 0.39950000000000013\n",
      "Error: 0.15999999999999992 Prediction: 0.40000000000000013\n",
      "Error: 0.15960024999999992 Prediction: 0.40050000000000013\n",
      "Error: 0.15920099999999993 Prediction: 0.40100000000000013\n",
      "Error: 0.15880224999999992 Prediction: 0.40150000000000013\n",
      "Error: 0.15840399999999993 Prediction: 0.40200000000000014\n",
      "Error: 0.15800624999999993 Prediction: 0.40250000000000014\n",
      "Error: 0.15760899999999992 Prediction: 0.40300000000000014\n",
      "Error: 0.15721224999999991 Prediction: 0.40350000000000014\n",
      "Error: 0.15681599999999993 Prediction: 0.40400000000000014\n",
      "Error: 0.15642024999999993 Prediction: 0.40450000000000014\n",
      "Error: 0.1560249999999999 Prediction: 0.40500000000000014\n",
      "Error: 0.15563024999999991 Prediction: 0.40550000000000014\n",
      "Error: 0.15523599999999993 Prediction: 0.40600000000000014\n",
      "Error: 0.15484224999999993 Prediction: 0.40650000000000014\n",
      "Error: 0.15444899999999992 Prediction: 0.40700000000000014\n",
      "Error: 0.15405624999999992 Prediction: 0.40750000000000014\n",
      "Error: 0.1536639999999999 Prediction: 0.40800000000000014\n",
      "Error: 0.15327224999999992 Prediction: 0.40850000000000014\n",
      "Error: 0.15288099999999993 Prediction: 0.40900000000000014\n",
      "Error: 0.1524902499999999 Prediction: 0.40950000000000014\n",
      "Error: 0.15209999999999993 Prediction: 0.41000000000000014\n",
      "Error: 0.15171024999999994 Prediction: 0.41050000000000014\n",
      "Error: 0.15132099999999993 Prediction: 0.41100000000000014\n",
      "Error: 0.15093224999999993 Prediction: 0.41150000000000014\n",
      "Error: 0.15054399999999993 Prediction: 0.41200000000000014\n",
      "Error: 0.15015624999999994 Prediction: 0.41250000000000014\n",
      "Error: 0.14976899999999993 Prediction: 0.41300000000000014\n",
      "Error: 0.1493822499999999 Prediction: 0.41350000000000015\n",
      "Error: 0.14899599999999993 Prediction: 0.41400000000000015\n",
      "Error: 0.14861024999999992 Prediction: 0.41450000000000015\n",
      "Error: 0.1482249999999999 Prediction: 0.41500000000000015\n",
      "Error: 0.14784024999999992 Prediction: 0.41550000000000015\n",
      "Error: 0.14745599999999992 Prediction: 0.41600000000000015\n",
      "Error: 0.14707224999999993 Prediction: 0.41650000000000015\n",
      "Error: 0.14668899999999993 Prediction: 0.41700000000000015\n",
      "Error: 0.14630624999999992 Prediction: 0.41750000000000015\n",
      "Error: 0.14592399999999991 Prediction: 0.41800000000000015\n",
      "Error: 0.14554224999999993 Prediction: 0.41850000000000015\n",
      "Error: 0.14516099999999993 Prediction: 0.41900000000000015\n",
      "Error: 0.14478024999999992 Prediction: 0.41950000000000015\n",
      "Error: 0.14439999999999992 Prediction: 0.42000000000000015\n",
      "Error: 0.1440202499999999 Prediction: 0.42050000000000015\n",
      "Error: 0.1436409999999999 Prediction: 0.42100000000000015\n",
      "Error: 0.14326224999999992 Prediction: 0.42150000000000015\n",
      "Error: 0.14288399999999993 Prediction: 0.42200000000000015\n",
      "Error: 0.14250624999999992 Prediction: 0.42250000000000015\n",
      "Error: 0.14212899999999992 Prediction: 0.42300000000000015\n",
      "Error: 0.1417522499999999 Prediction: 0.42350000000000015\n",
      "Error: 0.14137599999999992 Prediction: 0.42400000000000015\n",
      "Error: 0.1410002499999999 Prediction: 0.42450000000000015\n",
      "Error: 0.14062499999999992 Prediction: 0.42500000000000016\n",
      "Error: 0.1402502499999999 Prediction: 0.42550000000000016\n",
      "Error: 0.13987599999999992 Prediction: 0.42600000000000016\n",
      "Error: 0.1395022499999999 Prediction: 0.42650000000000016\n",
      "Error: 0.13912899999999992 Prediction: 0.42700000000000016\n",
      "Error: 0.13875624999999991 Prediction: 0.42750000000000016\n",
      "Error: 0.13838399999999992 Prediction: 0.42800000000000016\n",
      "Error: 0.13801224999999992 Prediction: 0.42850000000000016\n",
      "Error: 0.1376409999999999 Prediction: 0.42900000000000016\n",
      "Error: 0.13727024999999993 Prediction: 0.42950000000000016\n",
      "Error: 0.1368999999999999 Prediction: 0.43000000000000016\n",
      "Error: 0.1365302499999999 Prediction: 0.43050000000000016\n",
      "Error: 0.13616099999999992 Prediction: 0.43100000000000016\n",
      "Error: 0.13579224999999992 Prediction: 0.43150000000000016\n",
      "Error: 0.1354239999999999 Prediction: 0.43200000000000016\n",
      "Error: 0.1350562499999999 Prediction: 0.43250000000000016\n",
      "Error: 0.13468899999999992 Prediction: 0.43300000000000016\n",
      "Error: 0.13432224999999992 Prediction: 0.43350000000000016\n",
      "Error: 0.1339559999999999 Prediction: 0.43400000000000016\n",
      "Error: 0.1335902499999999 Prediction: 0.43450000000000016\n",
      "Error: 0.1332249999999999 Prediction: 0.43500000000000016\n",
      "Error: 0.1328602499999999 Prediction: 0.43550000000000016\n",
      "Error: 0.13249599999999992 Prediction: 0.43600000000000017\n",
      "Error: 0.13213224999999992 Prediction: 0.43650000000000017\n",
      "Error: 0.13176899999999991 Prediction: 0.43700000000000017\n",
      "Error: 0.13140624999999992 Prediction: 0.43750000000000017\n",
      "Error: 0.1310439999999999 Prediction: 0.43800000000000017\n",
      "Error: 0.13068224999999992 Prediction: 0.43850000000000017\n",
      "Error: 0.1303209999999999 Prediction: 0.43900000000000017\n",
      "Error: 0.12996024999999992 Prediction: 0.43950000000000017\n",
      "Error: 0.1295999999999999 Prediction: 0.44000000000000017\n",
      "Error: 0.12924024999999992 Prediction: 0.44050000000000017\n",
      "Error: 0.1288809999999999 Prediction: 0.44100000000000017\n",
      "Error: 0.12852224999999992 Prediction: 0.44150000000000017\n",
      "Error: 0.12816399999999992 Prediction: 0.44200000000000017\n",
      "Error: 0.1278062499999999 Prediction: 0.44250000000000017\n",
      "Error: 0.1274489999999999 Prediction: 0.44300000000000017\n",
      "Error: 0.1270922499999999 Prediction: 0.44350000000000017\n",
      "Error: 0.1267359999999999 Prediction: 0.4440000000000002\n",
      "Error: 0.12638024999999992 Prediction: 0.4445000000000002\n",
      "Error: 0.12602499999999991 Prediction: 0.4450000000000002\n",
      "Error: 0.1256702499999999 Prediction: 0.4455000000000002\n",
      "Error: 0.1253159999999999 Prediction: 0.4460000000000002\n",
      "Error: 0.12496224999999991 Prediction: 0.4465000000000002\n",
      "Error: 0.12460899999999991 Prediction: 0.4470000000000002\n",
      "Error: 0.1242562499999999 Prediction: 0.4475000000000002\n",
      "Error: 0.1239039999999999 Prediction: 0.4480000000000002\n",
      "Error: 0.1235522499999999 Prediction: 0.4485000000000002\n",
      "Error: 0.12320099999999991 Prediction: 0.4490000000000002\n",
      "Error: 0.12285024999999991 Prediction: 0.4495000000000002\n",
      "Error: 0.1224999999999999 Prediction: 0.4500000000000002\n",
      "Error: 0.1221502499999999 Prediction: 0.4505000000000002\n",
      "Error: 0.12180099999999991 Prediction: 0.4510000000000002\n",
      "Error: 0.1214522499999999 Prediction: 0.4515000000000002\n",
      "Error: 0.1211039999999999 Prediction: 0.4520000000000002\n",
      "Error: 0.12075624999999991 Prediction: 0.4525000000000002\n",
      "Error: 0.1204089999999999 Prediction: 0.4530000000000002\n",
      "Error: 0.12006224999999991 Prediction: 0.4535000000000002\n",
      "Error: 0.1197159999999999 Prediction: 0.4540000000000002\n",
      "Error: 0.1193702499999999 Prediction: 0.4545000000000002\n",
      "Error: 0.11902499999999991 Prediction: 0.4550000000000002\n",
      "Error: 0.1186802499999999 Prediction: 0.4555000000000002\n",
      "Error: 0.1183359999999999 Prediction: 0.4560000000000002\n",
      "Error: 0.11799224999999991 Prediction: 0.4565000000000002\n",
      "Error: 0.1176489999999999 Prediction: 0.4570000000000002\n",
      "Error: 0.1173062499999999 Prediction: 0.4575000000000002\n",
      "Error: 0.1169639999999999 Prediction: 0.4580000000000002\n",
      "Error: 0.1166222499999999 Prediction: 0.4585000000000002\n",
      "Error: 0.1162809999999999 Prediction: 0.4590000000000002\n",
      "Error: 0.1159402499999999 Prediction: 0.4595000000000002\n",
      "Error: 0.1155999999999999 Prediction: 0.4600000000000002\n",
      "Error: 0.1152602499999999 Prediction: 0.4605000000000002\n",
      "Error: 0.1149209999999999 Prediction: 0.4610000000000002\n",
      "Error: 0.1145822499999999 Prediction: 0.4615000000000002\n",
      "Error: 0.1142439999999999 Prediction: 0.4620000000000002\n",
      "Error: 0.1139062499999999 Prediction: 0.4625000000000002\n",
      "Error: 0.1135689999999999 Prediction: 0.4630000000000002\n",
      "Error: 0.1132322499999999 Prediction: 0.4635000000000002\n",
      "Error: 0.1128959999999999 Prediction: 0.4640000000000002\n",
      "Error: 0.1125602499999999 Prediction: 0.4645000000000002\n",
      "Error: 0.11222499999999991 Prediction: 0.4650000000000002\n",
      "Error: 0.1118902499999999 Prediction: 0.4655000000000002\n",
      "Error: 0.1115559999999999 Prediction: 0.4660000000000002\n",
      "Error: 0.1112222499999999 Prediction: 0.4665000000000002\n",
      "Error: 0.1108889999999999 Prediction: 0.4670000000000002\n",
      "Error: 0.1105562499999999 Prediction: 0.4675000000000002\n",
      "Error: 0.1102239999999999 Prediction: 0.4680000000000002\n",
      "Error: 0.1098922499999999 Prediction: 0.4685000000000002\n",
      "Error: 0.1095609999999999 Prediction: 0.4690000000000002\n",
      "Error: 0.1092302499999999 Prediction: 0.4695000000000002\n",
      "Error: 0.1088999999999999 Prediction: 0.4700000000000002\n",
      "Error: 0.1085702499999999 Prediction: 0.4705000000000002\n",
      "Error: 0.1082409999999999 Prediction: 0.4710000000000002\n",
      "Error: 0.1079122499999999 Prediction: 0.4715000000000002\n",
      "Error: 0.1075839999999999 Prediction: 0.4720000000000002\n",
      "Error: 0.1072562499999999 Prediction: 0.4725000000000002\n",
      "Error: 0.1069289999999999 Prediction: 0.4730000000000002\n",
      "Error: 0.1066022499999999 Prediction: 0.4735000000000002\n",
      "Error: 0.1062759999999999 Prediction: 0.4740000000000002\n",
      "Error: 0.1059502499999999 Prediction: 0.4745000000000002\n",
      "Error: 0.1056249999999999 Prediction: 0.4750000000000002\n",
      "Error: 0.1053002499999999 Prediction: 0.4755000000000002\n",
      "Error: 0.1049759999999999 Prediction: 0.4760000000000002\n",
      "Error: 0.1046522499999999 Prediction: 0.4765000000000002\n",
      "Error: 0.1043289999999999 Prediction: 0.4770000000000002\n",
      "Error: 0.1040062499999999 Prediction: 0.4775000000000002\n",
      "Error: 0.1036839999999999 Prediction: 0.4780000000000002\n",
      "Error: 0.10336224999999989 Prediction: 0.4785000000000002\n",
      "Error: 0.1030409999999999 Prediction: 0.4790000000000002\n",
      "Error: 0.1027202499999999 Prediction: 0.4795000000000002\n",
      "Error: 0.1023999999999999 Prediction: 0.4800000000000002\n",
      "Error: 0.1020802499999999 Prediction: 0.4805000000000002\n",
      "Error: 0.1017609999999999 Prediction: 0.4810000000000002\n",
      "Error: 0.1014422499999999 Prediction: 0.4815000000000002\n",
      "Error: 0.1011239999999999 Prediction: 0.4820000000000002\n",
      "Error: 0.1008062499999999 Prediction: 0.4825000000000002\n",
      "Error: 0.1004889999999999 Prediction: 0.4830000000000002\n",
      "Error: 0.1001722499999999 Prediction: 0.4835000000000002\n",
      "Error: 0.0998559999999999 Prediction: 0.4840000000000002\n",
      "Error: 0.0995402499999999 Prediction: 0.4845000000000002\n",
      "Error: 0.0992249999999999 Prediction: 0.4850000000000002\n",
      "Error: 0.0989102499999999 Prediction: 0.4855000000000002\n",
      "Error: 0.09859599999999989 Prediction: 0.4860000000000002\n",
      "Error: 0.09828224999999989 Prediction: 0.4865000000000002\n",
      "Error: 0.09796899999999989 Prediction: 0.4870000000000002\n",
      "Error: 0.0976562499999999 Prediction: 0.4875000000000002\n",
      "Error: 0.09734399999999989 Prediction: 0.4880000000000002\n",
      "Error: 0.09703224999999989 Prediction: 0.4885000000000002\n",
      "Error: 0.09672099999999989 Prediction: 0.4890000000000002\n",
      "Error: 0.09641024999999989 Prediction: 0.4895000000000002\n",
      "Error: 0.0960999999999999 Prediction: 0.4900000000000002\n",
      "Error: 0.0957902499999999 Prediction: 0.4905000000000002\n",
      "Error: 0.0954809999999999 Prediction: 0.4910000000000002\n",
      "Error: 0.09517224999999989 Prediction: 0.4915000000000002\n",
      "Error: 0.09486399999999989 Prediction: 0.4920000000000002\n",
      "Error: 0.0945562499999999 Prediction: 0.4925000000000002\n",
      "Error: 0.09424899999999989 Prediction: 0.4930000000000002\n",
      "Error: 0.0939422499999999 Prediction: 0.4935000000000002\n",
      "Error: 0.0936359999999999 Prediction: 0.4940000000000002\n",
      "Error: 0.09333024999999989 Prediction: 0.4945000000000002\n",
      "Error: 0.0930249999999999 Prediction: 0.4950000000000002\n",
      "Error: 0.09272024999999989 Prediction: 0.4955000000000002\n",
      "Error: 0.0924159999999999 Prediction: 0.4960000000000002\n",
      "Error: 0.0921122499999999 Prediction: 0.4965000000000002\n",
      "Error: 0.09180899999999989 Prediction: 0.4970000000000002\n",
      "Error: 0.0915062499999999 Prediction: 0.4975000000000002\n",
      "Error: 0.0912039999999999 Prediction: 0.4980000000000002\n",
      "Error: 0.09090224999999989 Prediction: 0.4985000000000002\n",
      "Error: 0.09060099999999989 Prediction: 0.4990000000000002\n",
      "Error: 0.09030024999999989 Prediction: 0.4995000000000002\n",
      "Error: 0.0899999999999999 Prediction: 0.5000000000000002\n",
      "Error: 0.08970024999999993 Prediction: 0.5005000000000002\n",
      "Error: 0.08940099999999995 Prediction: 0.5010000000000001\n",
      "Error: 0.08910225 Prediction: 0.5015000000000001\n",
      "Error: 0.08880400000000002 Prediction: 0.502\n",
      "Error: 0.08850625000000006 Prediction: 0.5025\n",
      "Error: 0.08820900000000009 Prediction: 0.5029999999999999\n",
      "Error: 0.08791225000000012 Prediction: 0.5034999999999998\n",
      "Error: 0.08761600000000015 Prediction: 0.5039999999999998\n",
      "Error: 0.08732025000000018 Prediction: 0.5044999999999997\n",
      "Error: 0.08702500000000021 Prediction: 0.5049999999999997\n",
      "Error: 0.08673025000000026 Prediction: 0.5054999999999996\n",
      "Error: 0.08643600000000029 Prediction: 0.5059999999999996\n",
      "Error: 0.08614225000000032 Prediction: 0.5064999999999995\n",
      "Error: 0.08584900000000034 Prediction: 0.5069999999999995\n",
      "Error: 0.08555625000000038 Prediction: 0.5074999999999994\n",
      "Error: 0.08526400000000041 Prediction: 0.5079999999999993\n",
      "Error: 0.08497225000000044 Prediction: 0.5084999999999993\n",
      "Error: 0.08468100000000048 Prediction: 0.5089999999999992\n",
      "Error: 0.0843902500000005 Prediction: 0.5094999999999992\n",
      "Error: 0.08410000000000054 Prediction: 0.5099999999999991\n",
      "Error: 0.08381025000000057 Prediction: 0.5104999999999991\n",
      "Error: 0.0835210000000006 Prediction: 0.510999999999999\n",
      "Error: 0.08323225000000063 Prediction: 0.511499999999999\n",
      "Error: 0.08294400000000066 Prediction: 0.5119999999999989\n",
      "Error: 0.0826562500000007 Prediction: 0.5124999999999988\n",
      "Error: 0.08236900000000072 Prediction: 0.5129999999999988\n",
      "Error: 0.08208225000000074 Prediction: 0.5134999999999987\n",
      "Error: 0.08179600000000078 Prediction: 0.5139999999999987\n",
      "Error: 0.08151025000000081 Prediction: 0.5144999999999986\n",
      "Error: 0.08122500000000084 Prediction: 0.5149999999999986\n",
      "Error: 0.08094025000000087 Prediction: 0.5154999999999985\n",
      "Error: 0.0806560000000009 Prediction: 0.5159999999999985\n",
      "Error: 0.08037225000000094 Prediction: 0.5164999999999984\n",
      "Error: 0.08008900000000096 Prediction: 0.5169999999999983\n",
      "Error: 0.079806250000001 Prediction: 0.5174999999999983\n",
      "Error: 0.07952400000000102 Prediction: 0.5179999999999982\n",
      "Error: 0.07924225000000104 Prediction: 0.5184999999999982\n",
      "Error: 0.07896100000000107 Prediction: 0.5189999999999981\n",
      "Error: 0.0786802500000011 Prediction: 0.5194999999999981\n",
      "Error: 0.07840000000000114 Prediction: 0.519999999999998\n",
      "Error: 0.07812025000000117 Prediction: 0.520499999999998\n",
      "Error: 0.07784100000000119 Prediction: 0.5209999999999979\n",
      "Error: 0.07756225000000122 Prediction: 0.5214999999999979\n",
      "Error: 0.07728400000000125 Prediction: 0.5219999999999978\n",
      "Error: 0.07700625000000128 Prediction: 0.5224999999999977\n",
      "Error: 0.07672900000000131 Prediction: 0.5229999999999977\n",
      "Error: 0.07645225000000133 Prediction: 0.5234999999999976\n",
      "Error: 0.07617600000000137 Prediction: 0.5239999999999976\n",
      "Error: 0.07590025000000139 Prediction: 0.5244999999999975\n",
      "Error: 0.07562500000000141 Prediction: 0.5249999999999975\n",
      "Error: 0.07535025000000145 Prediction: 0.5254999999999974\n",
      "Error: 0.07507600000000147 Prediction: 0.5259999999999974\n",
      "Error: 0.0748022500000015 Prediction: 0.5264999999999973\n",
      "Error: 0.07452900000000152 Prediction: 0.5269999999999972\n",
      "Error: 0.07425625000000155 Prediction: 0.5274999999999972\n",
      "Error: 0.07398400000000158 Prediction: 0.5279999999999971\n",
      "Error: 0.0737122500000016 Prediction: 0.5284999999999971\n",
      "Error: 0.07344100000000163 Prediction: 0.528999999999997\n",
      "Error: 0.07317025000000166 Prediction: 0.529499999999997\n",
      "Error: 0.07290000000000169 Prediction: 0.5299999999999969\n",
      "Error: 0.07263025000000171 Prediction: 0.5304999999999969\n",
      "Error: 0.07236100000000174 Prediction: 0.5309999999999968\n",
      "Error: 0.07209225000000177 Prediction: 0.5314999999999968\n",
      "Error: 0.07182400000000179 Prediction: 0.5319999999999967\n",
      "Error: 0.07155625000000182 Prediction: 0.5324999999999966\n",
      "Error: 0.07128900000000185 Prediction: 0.5329999999999966\n",
      "Error: 0.07102225000000187 Prediction: 0.5334999999999965\n",
      "Error: 0.0707560000000019 Prediction: 0.5339999999999965\n",
      "Error: 0.07049025000000192 Prediction: 0.5344999999999964\n",
      "Error: 0.07022500000000195 Prediction: 0.5349999999999964\n",
      "Error: 0.06996025000000197 Prediction: 0.5354999999999963\n",
      "Error: 0.069696000000002 Prediction: 0.5359999999999963\n",
      "Error: 0.06943225000000203 Prediction: 0.5364999999999962\n",
      "Error: 0.06916900000000205 Prediction: 0.5369999999999961\n",
      "Error: 0.06890625000000207 Prediction: 0.5374999999999961\n",
      "Error: 0.0686440000000021 Prediction: 0.537999999999996\n",
      "Error: 0.06838225000000213 Prediction: 0.538499999999996\n",
      "Error: 0.06812100000000215 Prediction: 0.5389999999999959\n",
      "Error: 0.06786025000000218 Prediction: 0.5394999999999959\n",
      "Error: 0.0676000000000022 Prediction: 0.5399999999999958\n",
      "Error: 0.06734025000000222 Prediction: 0.5404999999999958\n",
      "Error: 0.06708100000000225 Prediction: 0.5409999999999957\n",
      "Error: 0.06682225000000228 Prediction: 0.5414999999999957\n",
      "Error: 0.0665640000000023 Prediction: 0.5419999999999956\n",
      "Error: 0.06630625000000231 Prediction: 0.5424999999999955\n",
      "Error: 0.06604900000000234 Prediction: 0.5429999999999955\n",
      "Error: 0.06579225000000237 Prediction: 0.5434999999999954\n",
      "Error: 0.06553600000000238 Prediction: 0.5439999999999954\n",
      "Error: 0.06528025000000241 Prediction: 0.5444999999999953\n",
      "Error: 0.06502500000000244 Prediction: 0.5449999999999953\n",
      "Error: 0.06477025000000246 Prediction: 0.5454999999999952\n",
      "Error: 0.06451600000000249 Prediction: 0.5459999999999952\n",
      "Error: 0.0642622500000025 Prediction: 0.5464999999999951\n",
      "Error: 0.06400900000000254 Prediction: 0.546999999999995\n",
      "Error: 0.06375625000000255 Prediction: 0.547499999999995\n",
      "Error: 0.06350400000000257 Prediction: 0.5479999999999949\n",
      "Error: 0.06325225000000259 Prediction: 0.5484999999999949\n",
      "Error: 0.06300100000000262 Prediction: 0.5489999999999948\n",
      "Error: 0.06275025000000264 Prediction: 0.5494999999999948\n",
      "Error: 0.06250000000000266 Prediction: 0.5499999999999947\n",
      "Error: 0.062250250000002685 Prediction: 0.5504999999999947\n",
      "Error: 0.06200100000000271 Prediction: 0.5509999999999946\n",
      "Error: 0.06175225000000273 Prediction: 0.5514999999999946\n",
      "Error: 0.06150400000000275 Prediction: 0.5519999999999945\n",
      "Error: 0.061256250000002774 Prediction: 0.5524999999999944\n",
      "Error: 0.0610090000000028 Prediction: 0.5529999999999944\n",
      "Error: 0.060762250000002814 Prediction: 0.5534999999999943\n",
      "Error: 0.06051600000000284 Prediction: 0.5539999999999943\n",
      "Error: 0.06027025000000286 Prediction: 0.5544999999999942\n",
      "Error: 0.06002500000000288 Prediction: 0.5549999999999942\n",
      "Error: 0.0597802500000029 Prediction: 0.5554999999999941\n",
      "Error: 0.05953600000000292 Prediction: 0.555999999999994\n",
      "Error: 0.05929225000000295 Prediction: 0.556499999999994\n",
      "Error: 0.05904900000000297 Prediction: 0.5569999999999939\n",
      "Error: 0.05880625000000299 Prediction: 0.5574999999999939\n",
      "Error: 0.058564000000003 Prediction: 0.5579999999999938\n",
      "Error: 0.058322250000003024 Prediction: 0.5584999999999938\n",
      "Error: 0.05808100000000305 Prediction: 0.5589999999999937\n",
      "Error: 0.05784025000000307 Prediction: 0.5594999999999937\n",
      "Error: 0.057600000000003086 Prediction: 0.5599999999999936\n",
      "Error: 0.0573602500000031 Prediction: 0.5604999999999936\n",
      "Error: 0.05712100000000313 Prediction: 0.5609999999999935\n",
      "Error: 0.056882250000003146 Prediction: 0.5614999999999934\n",
      "Error: 0.056644000000003164 Prediction: 0.5619999999999934\n",
      "Error: 0.05640625000000318 Prediction: 0.5624999999999933\n",
      "Error: 0.0561690000000032 Prediction: 0.5629999999999933\n",
      "Error: 0.05593225000000322 Prediction: 0.5634999999999932\n",
      "Error: 0.05569600000000324 Prediction: 0.5639999999999932\n",
      "Error: 0.055460250000003264 Prediction: 0.5644999999999931\n",
      "Error: 0.05522500000000328 Prediction: 0.5649999999999931\n",
      "Error: 0.0549902500000033 Prediction: 0.565499999999993\n",
      "Error: 0.054756000000003316 Prediction: 0.565999999999993\n",
      "Error: 0.05452225000000334 Prediction: 0.5664999999999929\n",
      "Error: 0.054289000000003355 Prediction: 0.5669999999999928\n",
      "Error: 0.05405625000000337 Prediction: 0.5674999999999928\n",
      "Error: 0.05382400000000339 Prediction: 0.5679999999999927\n",
      "Error: 0.05359225000000341 Prediction: 0.5684999999999927\n",
      "Error: 0.053361000000003427 Prediction: 0.5689999999999926\n",
      "Error: 0.053130250000003446 Prediction: 0.5694999999999926\n",
      "Error: 0.052900000000003465 Prediction: 0.5699999999999925\n",
      "Error: 0.052670250000003485 Prediction: 0.5704999999999925\n",
      "Error: 0.0524410000000035 Prediction: 0.5709999999999924\n",
      "Error: 0.05221225000000352 Prediction: 0.5714999999999923\n",
      "Error: 0.051984000000003534 Prediction: 0.5719999999999923\n",
      "Error: 0.05175625000000355 Prediction: 0.5724999999999922\n",
      "Error: 0.05152900000000357 Prediction: 0.5729999999999922\n",
      "Error: 0.05130225000000359 Prediction: 0.5734999999999921\n",
      "Error: 0.051076000000003605 Prediction: 0.5739999999999921\n",
      "Error: 0.05085025000000362 Prediction: 0.574499999999992\n",
      "Error: 0.05062500000000364 Prediction: 0.574999999999992\n",
      "Error: 0.05040025000000365 Prediction: 0.5754999999999919\n",
      "Error: 0.05017600000000367 Prediction: 0.5759999999999919\n",
      "Error: 0.04995225000000369 Prediction: 0.5764999999999918\n",
      "Error: 0.0497290000000037 Prediction: 0.5769999999999917\n",
      "Error: 0.04950625000000372 Prediction: 0.5774999999999917\n",
      "Error: 0.049284000000003735 Prediction: 0.5779999999999916\n",
      "Error: 0.04906225000000375 Prediction: 0.5784999999999916\n",
      "Error: 0.04884100000000377 Prediction: 0.5789999999999915\n",
      "Error: 0.048620250000003785 Prediction: 0.5794999999999915\n",
      "Error: 0.0484000000000038 Prediction: 0.5799999999999914\n",
      "Error: 0.04818025000000382 Prediction: 0.5804999999999914\n",
      "Error: 0.04796100000000383 Prediction: 0.5809999999999913\n",
      "Error: 0.047742250000003844 Prediction: 0.5814999999999912\n",
      "Error: 0.04752400000000386 Prediction: 0.5819999999999912\n",
      "Error: 0.04730625000000387 Prediction: 0.5824999999999911\n",
      "Error: 0.04708900000000389 Prediction: 0.5829999999999911\n",
      "Error: 0.046872250000003904 Prediction: 0.583499999999991\n",
      "Error: 0.04665600000000392 Prediction: 0.583999999999991\n",
      "Error: 0.04644025000000394 Prediction: 0.5844999999999909\n",
      "Error: 0.04622500000000395 Prediction: 0.5849999999999909\n",
      "Error: 0.046010250000003965 Prediction: 0.5854999999999908\n",
      "Error: 0.04579600000000398 Prediction: 0.5859999999999908\n",
      "Error: 0.045582250000003995 Prediction: 0.5864999999999907\n",
      "Error: 0.045369000000004 Prediction: 0.5869999999999906\n",
      "Error: 0.04515625000000402 Prediction: 0.5874999999999906\n",
      "Error: 0.044944000000004036 Prediction: 0.5879999999999905\n",
      "Error: 0.04473225000000405 Prediction: 0.5884999999999905\n",
      "Error: 0.044521000000004064 Prediction: 0.5889999999999904\n",
      "Error: 0.044310250000004076 Prediction: 0.5894999999999904\n",
      "Error: 0.04410000000000409 Prediction: 0.5899999999999903\n",
      "Error: 0.0438902500000041 Prediction: 0.5904999999999903\n",
      "Error: 0.04368100000000411 Prediction: 0.5909999999999902\n",
      "Error: 0.043472250000004126 Prediction: 0.5914999999999901\n",
      "Error: 0.04326400000000414 Prediction: 0.5919999999999901\n",
      "Error: 0.043056250000004154 Prediction: 0.59249999999999\n",
      "Error: 0.04284900000000417 Prediction: 0.59299999999999\n",
      "Error: 0.04264225000000418 Prediction: 0.5934999999999899\n",
      "Error: 0.04243600000000419 Prediction: 0.5939999999999899\n",
      "Error: 0.0422302500000042 Prediction: 0.5944999999999898\n",
      "Error: 0.04202500000000422 Prediction: 0.5949999999999898\n",
      "Error: 0.04182025000000423 Prediction: 0.5954999999999897\n",
      "Error: 0.04161600000000424 Prediction: 0.5959999999999896\n",
      "Error: 0.04141225000000425 Prediction: 0.5964999999999896\n",
      "Error: 0.04120900000000426 Prediction: 0.5969999999999895\n",
      "Error: 0.041006250000004275 Prediction: 0.5974999999999895\n",
      "Error: 0.04080400000000429 Prediction: 0.5979999999999894\n",
      "Error: 0.0406022500000043 Prediction: 0.5984999999999894\n",
      "Error: 0.04040100000000431 Prediction: 0.5989999999999893\n",
      "Error: 0.04020025000000432 Prediction: 0.5994999999999893\n",
      "Error: 0.04000000000000434 Prediction: 0.5999999999999892\n",
      "Error: 0.039800250000004346 Prediction: 0.6004999999999892\n",
      "Error: 0.039601000000004355 Prediction: 0.6009999999999891\n",
      "Error: 0.039402250000004364 Prediction: 0.601499999999989\n",
      "Error: 0.03920400000000438 Prediction: 0.601999999999989\n",
      "Error: 0.03900625000000439 Prediction: 0.6024999999999889\n",
      "Error: 0.0388090000000044 Prediction: 0.6029999999999889\n",
      "Error: 0.03861225000000441 Prediction: 0.6034999999999888\n",
      "Error: 0.03841600000000442 Prediction: 0.6039999999999888\n",
      "Error: 0.03822025000000443 Prediction: 0.6044999999999887\n",
      "Error: 0.038025000000004444 Prediction: 0.6049999999999887\n",
      "Error: 0.03783025000000445 Prediction: 0.6054999999999886\n",
      "Error: 0.03763600000000446 Prediction: 0.6059999999999885\n",
      "Error: 0.03744225000000447 Prediction: 0.6064999999999885\n",
      "Error: 0.03724900000000448 Prediction: 0.6069999999999884\n",
      "Error: 0.03705625000000449 Prediction: 0.6074999999999884\n",
      "Error: 0.0368640000000045 Prediction: 0.6079999999999883\n",
      "Error: 0.03667225000000451 Prediction: 0.6084999999999883\n",
      "Error: 0.03648100000000452 Prediction: 0.6089999999999882\n",
      "Error: 0.03629025000000453 Prediction: 0.6094999999999882\n",
      "Error: 0.03610000000000454 Prediction: 0.6099999999999881\n",
      "Error: 0.03591025000000454 Prediction: 0.610499999999988\n",
      "Error: 0.035721000000004555 Prediction: 0.610999999999988\n",
      "Error: 0.03553225000000456 Prediction: 0.6114999999999879\n",
      "Error: 0.03534400000000457 Prediction: 0.6119999999999879\n",
      "Error: 0.03515625000000458 Prediction: 0.6124999999999878\n",
      "Error: 0.03496900000000459 Prediction: 0.6129999999999878\n",
      "Error: 0.034782250000004594 Prediction: 0.6134999999999877\n",
      "Error: 0.0345960000000046 Prediction: 0.6139999999999877\n",
      "Error: 0.03441025000000461 Prediction: 0.6144999999999876\n",
      "Error: 0.03422500000000462 Prediction: 0.6149999999999876\n",
      "Error: 0.03404025000000463 Prediction: 0.6154999999999875\n",
      "Error: 0.03385600000000464 Prediction: 0.6159999999999874\n",
      "Error: 0.03367225000000464 Prediction: 0.6164999999999874\n",
      "Error: 0.033489000000004654 Prediction: 0.6169999999999873\n",
      "Error: 0.03330625000000466 Prediction: 0.6174999999999873\n",
      "Error: 0.033124000000004664 Prediction: 0.6179999999999872\n",
      "Error: 0.032942250000004676 Prediction: 0.6184999999999872\n",
      "Error: 0.03276100000000468 Prediction: 0.6189999999999871\n",
      "Error: 0.03258025000000469 Prediction: 0.6194999999999871\n",
      "Error: 0.032400000000004696 Prediction: 0.619999999999987\n",
      "Error: 0.0322202500000047 Prediction: 0.620499999999987\n",
      "Error: 0.032041000000004705 Prediction: 0.6209999999999869\n",
      "Error: 0.03186225000000471 Prediction: 0.6214999999999868\n",
      "Error: 0.03168400000000472 Prediction: 0.6219999999999868\n",
      "Error: 0.031506250000004725 Prediction: 0.6224999999999867\n",
      "Error: 0.031329000000004735 Prediction: 0.6229999999999867\n",
      "Error: 0.03115225000000474 Prediction: 0.6234999999999866\n",
      "Error: 0.030976000000004746 Prediction: 0.6239999999999866\n",
      "Error: 0.03080025000000475 Prediction: 0.6244999999999865\n",
      "Error: 0.030625000000004756 Prediction: 0.6249999999999865\n",
      "Error: 0.03045025000000476 Prediction: 0.6254999999999864\n",
      "Error: 0.030276000000004768 Prediction: 0.6259999999999863\n",
      "Error: 0.03010225000000477 Prediction: 0.6264999999999863\n",
      "Error: 0.029929000000004778 Prediction: 0.6269999999999862\n",
      "Error: 0.029756250000004782 Prediction: 0.6274999999999862\n",
      "Error: 0.029584000000004787 Prediction: 0.6279999999999861\n",
      "Error: 0.029412250000004792 Prediction: 0.6284999999999861\n",
      "Error: 0.029241000000004798 Prediction: 0.628999999999986\n",
      "Error: 0.029070250000004804 Prediction: 0.629499999999986\n",
      "Error: 0.028900000000004807 Prediction: 0.6299999999999859\n",
      "Error: 0.02873025000000481 Prediction: 0.6304999999999858\n",
      "Error: 0.028561000000004815 Prediction: 0.6309999999999858\n",
      "Error: 0.02839225000000482 Prediction: 0.6314999999999857\n",
      "Error: 0.028224000000004825 Prediction: 0.6319999999999857\n",
      "Error: 0.02805625000000483 Prediction: 0.6324999999999856\n",
      "Error: 0.027889000000004834 Prediction: 0.6329999999999856\n",
      "Error: 0.027722250000004837 Prediction: 0.6334999999999855\n",
      "Error: 0.02755600000000484 Prediction: 0.6339999999999855\n",
      "Error: 0.027390250000004845 Prediction: 0.6344999999999854\n",
      "Error: 0.02722500000000485 Prediction: 0.6349999999999854\n",
      "Error: 0.02706025000000485 Prediction: 0.6354999999999853\n",
      "Error: 0.026896000000004854 Prediction: 0.6359999999999852\n",
      "Error: 0.026732250000004856 Prediction: 0.6364999999999852\n",
      "Error: 0.02656900000000486 Prediction: 0.6369999999999851\n",
      "Error: 0.026406250000004863 Prediction: 0.6374999999999851\n",
      "Error: 0.026244000000004868 Prediction: 0.637999999999985\n",
      "Error: 0.02608225000000487 Prediction: 0.638499999999985\n",
      "Error: 0.02592100000000487 Prediction: 0.6389999999999849\n",
      "Error: 0.025760250000004873 Prediction: 0.6394999999999849\n",
      "Error: 0.025600000000004876 Prediction: 0.6399999999999848\n",
      "Error: 0.02544025000000488 Prediction: 0.6404999999999847\n",
      "Error: 0.025281000000004883 Prediction: 0.6409999999999847\n",
      "Error: 0.025122250000004884 Prediction: 0.6414999999999846\n",
      "Error: 0.024964000000004885 Prediction: 0.6419999999999846\n",
      "Error: 0.024806250000004887 Prediction: 0.6424999999999845\n",
      "Error: 0.02464900000000489 Prediction: 0.6429999999999845\n",
      "Error: 0.024492250000004892 Prediction: 0.6434999999999844\n",
      "Error: 0.024336000000004892 Prediction: 0.6439999999999844\n",
      "Error: 0.024180250000004896 Prediction: 0.6444999999999843\n",
      "Error: 0.024025000000004897 Prediction: 0.6449999999999843\n",
      "Error: 0.023870250000004898 Prediction: 0.6454999999999842\n",
      "Error: 0.023716000000004896 Prediction: 0.6459999999999841\n",
      "Error: 0.0235622500000049 Prediction: 0.6464999999999841\n",
      "Error: 0.023409000000004898 Prediction: 0.646999999999984\n",
      "Error: 0.0232562500000049 Prediction: 0.647499999999984\n",
      "Error: 0.023104000000004902 Prediction: 0.6479999999999839\n",
      "Error: 0.022952250000004903 Prediction: 0.6484999999999839\n",
      "Error: 0.0228010000000049 Prediction: 0.6489999999999838\n",
      "Error: 0.022650250000004903 Prediction: 0.6494999999999838\n",
      "Error: 0.0225000000000049 Prediction: 0.6499999999999837\n",
      "Error: 0.022350250000004904 Prediction: 0.6504999999999836\n",
      "Error: 0.022201000000004904 Prediction: 0.6509999999999836\n",
      "Error: 0.0220522500000049 Prediction: 0.6514999999999835\n",
      "Error: 0.021904000000004902 Prediction: 0.6519999999999835\n",
      "Error: 0.021756250000004904 Prediction: 0.6524999999999834\n",
      "Error: 0.021609000000004902 Prediction: 0.6529999999999834\n",
      "Error: 0.0214622500000049 Prediction: 0.6534999999999833\n",
      "Error: 0.0213160000000049 Prediction: 0.6539999999999833\n",
      "Error: 0.0211702500000049 Prediction: 0.6544999999999832\n",
      "Error: 0.021025000000004897 Prediction: 0.6549999999999832\n",
      "Error: 0.0208802500000049 Prediction: 0.6554999999999831\n",
      "Error: 0.020736000000004896 Prediction: 0.655999999999983\n",
      "Error: 0.020592250000004895 Prediction: 0.656499999999983\n",
      "Error: 0.020449000000004894 Prediction: 0.6569999999999829\n",
      "Error: 0.020306250000004893 Prediction: 0.6574999999999829\n",
      "Error: 0.02016400000000489 Prediction: 0.6579999999999828\n",
      "Error: 0.02002225000000489 Prediction: 0.6584999999999828\n",
      "Error: 0.019881000000004888 Prediction: 0.6589999999999827\n",
      "Error: 0.019740250000004886 Prediction: 0.6594999999999827\n",
      "Error: 0.019600000000004884 Prediction: 0.6599999999999826\n",
      "Error: 0.019460250000004883 Prediction: 0.6604999999999825\n",
      "Error: 0.01932100000000488 Prediction: 0.6609999999999825\n",
      "Error: 0.01918225000000488 Prediction: 0.6614999999999824\n",
      "Error: 0.019044000000004876 Prediction: 0.6619999999999824\n",
      "Error: 0.018906250000004874 Prediction: 0.6624999999999823\n",
      "Error: 0.01876900000000487 Prediction: 0.6629999999999823\n",
      "Error: 0.018632250000004867 Prediction: 0.6634999999999822\n",
      "Error: 0.018496000000004866 Prediction: 0.6639999999999822\n",
      "Error: 0.018360250000004862 Prediction: 0.6644999999999821\n",
      "Error: 0.01822500000000486 Prediction: 0.664999999999982\n",
      "Error: 0.018090250000004856 Prediction: 0.665499999999982\n",
      "Error: 0.017956000000004853 Prediction: 0.6659999999999819\n",
      "Error: 0.017822250000004848 Prediction: 0.6664999999999819\n",
      "Error: 0.017689000000004847 Prediction: 0.6669999999999818\n",
      "Error: 0.017556250000004842 Prediction: 0.6674999999999818\n",
      "Error: 0.01742400000000484 Prediction: 0.6679999999999817\n",
      "Error: 0.017292250000004835 Prediction: 0.6684999999999817\n",
      "Error: 0.01716100000000483 Prediction: 0.6689999999999816\n",
      "Error: 0.017030250000004826 Prediction: 0.6694999999999816\n",
      "Error: 0.01690000000000482 Prediction: 0.6699999999999815\n",
      "Error: 0.016770250000004816 Prediction: 0.6704999999999814\n",
      "Error: 0.01664100000000481 Prediction: 0.6709999999999814\n",
      "Error: 0.016512250000004808 Prediction: 0.6714999999999813\n",
      "Error: 0.016384000000004804 Prediction: 0.6719999999999813\n",
      "Error: 0.016256250000004798 Prediction: 0.6724999999999812\n",
      "Error: 0.016129000000004796 Prediction: 0.6729999999999812\n",
      "Error: 0.01600225000000479 Prediction: 0.6734999999999811\n",
      "Error: 0.015876000000004786 Prediction: 0.6739999999999811\n",
      "Error: 0.015750250000004778 Prediction: 0.674499999999981\n",
      "Error: 0.015625000000004774 Prediction: 0.674999999999981\n",
      "Error: 0.015500250000004769 Prediction: 0.6754999999999809\n",
      "Error: 0.015376000000004763 Prediction: 0.6759999999999808\n",
      "Error: 0.015252250000004757 Prediction: 0.6764999999999808\n",
      "Error: 0.015129000000004751 Prediction: 0.6769999999999807\n",
      "Error: 0.015006250000004747 Prediction: 0.6774999999999807\n",
      "Error: 0.01488400000000474 Prediction: 0.6779999999999806\n",
      "Error: 0.014762250000004733 Prediction: 0.6784999999999806\n",
      "Error: 0.014641000000004728 Prediction: 0.6789999999999805\n",
      "Error: 0.014520250000004722 Prediction: 0.6794999999999805\n",
      "Error: 0.014400000000004715 Prediction: 0.6799999999999804\n",
      "Error: 0.01428025000000471 Prediction: 0.6804999999999803\n",
      "Error: 0.014161000000004703 Prediction: 0.6809999999999803\n",
      "Error: 0.014042250000004695 Prediction: 0.6814999999999802\n",
      "Error: 0.013924000000004688 Prediction: 0.6819999999999802\n",
      "Error: 0.013806250000004681 Prediction: 0.6824999999999801\n",
      "Error: 0.013689000000004675 Prediction: 0.6829999999999801\n",
      "Error: 0.013572250000004667 Prediction: 0.68349999999998\n",
      "Error: 0.01345600000000466 Prediction: 0.68399999999998\n",
      "Error: 0.013340250000004652 Prediction: 0.6844999999999799\n",
      "Error: 0.013225000000004644 Prediction: 0.6849999999999798\n",
      "Error: 0.013110250000004637 Prediction: 0.6854999999999798\n",
      "Error: 0.01299600000000463 Prediction: 0.6859999999999797\n",
      "Error: 0.012882250000004623 Prediction: 0.6864999999999797\n",
      "Error: 0.012769000000004615 Prediction: 0.6869999999999796\n",
      "Error: 0.012656250000004607 Prediction: 0.6874999999999796\n",
      "Error: 0.012544000000004598 Prediction: 0.6879999999999795\n",
      "Error: 0.01243225000000459 Prediction: 0.6884999999999795\n",
      "Error: 0.012321000000004582 Prediction: 0.6889999999999794\n",
      "Error: 0.012210250000004573 Prediction: 0.6894999999999794\n",
      "Error: 0.012100000000004564 Prediction: 0.6899999999999793\n",
      "Error: 0.011990250000004556 Prediction: 0.6904999999999792\n",
      "Error: 0.011881000000004548 Prediction: 0.6909999999999792\n",
      "Error: 0.011772250000004538 Prediction: 0.6914999999999791\n",
      "Error: 0.011664000000004528 Prediction: 0.6919999999999791\n",
      "Error: 0.01155625000000452 Prediction: 0.692499999999979\n",
      "Error: 0.011449000000004511 Prediction: 0.692999999999979\n",
      "Error: 0.011342250000004502 Prediction: 0.6934999999999789\n",
      "Error: 0.011236000000004492 Prediction: 0.6939999999999789\n",
      "Error: 0.011130250000004482 Prediction: 0.6944999999999788\n",
      "Error: 0.011025000000004472 Prediction: 0.6949999999999787\n",
      "Error: 0.010920250000004463 Prediction: 0.6954999999999787\n",
      "Error: 0.010816000000004452 Prediction: 0.6959999999999786\n",
      "Error: 0.010712250000004442 Prediction: 0.6964999999999786\n",
      "Error: 0.010609000000004433 Prediction: 0.6969999999999785\n",
      "Error: 0.010506250000004422 Prediction: 0.6974999999999785\n",
      "Error: 0.010404000000004411 Prediction: 0.6979999999999784\n",
      "Error: 0.010302250000004402 Prediction: 0.6984999999999784\n",
      "Error: 0.01020100000000439 Prediction: 0.6989999999999783\n",
      "Error: 0.01010025000000438 Prediction: 0.6994999999999783\n",
      "Error: 0.01000000000000437 Prediction: 0.6999999999999782\n",
      "Error: 0.009900250000004359 Prediction: 0.7004999999999781\n",
      "Error: 0.009801000000004348 Prediction: 0.7009999999999781\n",
      "Error: 0.009702250000004338 Prediction: 0.701499999999978\n",
      "Error: 0.009604000000004326 Prediction: 0.701999999999978\n",
      "Error: 0.009506250000004315 Prediction: 0.7024999999999779\n",
      "Error: 0.009409000000004303 Prediction: 0.7029999999999779\n",
      "Error: 0.009312250000004291 Prediction: 0.7034999999999778\n",
      "Error: 0.00921600000000428 Prediction: 0.7039999999999778\n",
      "Error: 0.009120250000004267 Prediction: 0.7044999999999777\n",
      "Error: 0.009025000000004255 Prediction: 0.7049999999999776\n",
      "Error: 0.008930250000004244 Prediction: 0.7054999999999776\n",
      "Error: 0.008836000000004231 Prediction: 0.7059999999999775\n",
      "Error: 0.008742250000004219 Prediction: 0.7064999999999775\n",
      "Error: 0.008649000000004207 Prediction: 0.7069999999999774\n",
      "Error: 0.008556250000004194 Prediction: 0.7074999999999774\n",
      "Error: 0.008464000000004182 Prediction: 0.7079999999999773\n",
      "Error: 0.00837225000000417 Prediction: 0.7084999999999773\n",
      "Error: 0.008281000000004157 Prediction: 0.7089999999999772\n",
      "Error: 0.008190250000004144 Prediction: 0.7094999999999771\n",
      "Error: 0.008100000000004132 Prediction: 0.7099999999999771\n",
      "Error: 0.008010250000004118 Prediction: 0.710499999999977\n",
      "Error: 0.007921000000004105 Prediction: 0.710999999999977\n",
      "Error: 0.007832250000004091 Prediction: 0.7114999999999769\n",
      "Error: 0.007744000000004078 Prediction: 0.7119999999999769\n",
      "Error: 0.007656250000004064 Prediction: 0.7124999999999768\n",
      "Error: 0.007569000000004051 Prediction: 0.7129999999999768\n",
      "Error: 0.007482250000004037 Prediction: 0.7134999999999767\n",
      "Error: 0.0073960000000040235 Prediction: 0.7139999999999767\n",
      "Error: 0.00731025000000401 Prediction: 0.7144999999999766\n",
      "Error: 0.007225000000003996 Prediction: 0.7149999999999765\n",
      "Error: 0.007140250000003981 Prediction: 0.7154999999999765\n",
      "Error: 0.007056000000003967 Prediction: 0.7159999999999764\n",
      "Error: 0.006972250000003953 Prediction: 0.7164999999999764\n",
      "Error: 0.006889000000003938 Prediction: 0.7169999999999763\n",
      "Error: 0.006806250000003923 Prediction: 0.7174999999999763\n",
      "Error: 0.006724000000003908 Prediction: 0.7179999999999762\n",
      "Error: 0.006642250000003893 Prediction: 0.7184999999999762\n",
      "Error: 0.006561000000003879 Prediction: 0.7189999999999761\n",
      "Error: 0.006480250000003863 Prediction: 0.719499999999976\n",
      "Error: 0.006400000000003848 Prediction: 0.719999999999976\n",
      "Error: 0.006320250000003833 Prediction: 0.7204999999999759\n",
      "Error: 0.006241000000003817 Prediction: 0.7209999999999759\n",
      "Error: 0.006162250000003802 Prediction: 0.7214999999999758\n",
      "Error: 0.006084000000003786 Prediction: 0.7219999999999758\n",
      "Error: 0.006006250000003771 Prediction: 0.7224999999999757\n",
      "Error: 0.005929000000003755 Prediction: 0.7229999999999757\n",
      "Error: 0.005852250000003739 Prediction: 0.7234999999999756\n",
      "Error: 0.005776000000003723 Prediction: 0.7239999999999756\n",
      "Error: 0.005700250000003707 Prediction: 0.7244999999999755\n",
      "Error: 0.00562500000000369 Prediction: 0.7249999999999754\n",
      "Error: 0.005550250000003674 Prediction: 0.7254999999999754\n",
      "Error: 0.005476000000003658 Prediction: 0.7259999999999753\n",
      "Error: 0.005402250000003641 Prediction: 0.7264999999999753\n",
      "Error: 0.005329000000003624 Prediction: 0.7269999999999752\n",
      "Error: 0.005256250000003607 Prediction: 0.7274999999999752\n",
      "Error: 0.00518400000000359 Prediction: 0.7279999999999751\n",
      "Error: 0.005112250000003573 Prediction: 0.7284999999999751\n",
      "Error: 0.0050410000000035565 Prediction: 0.728999999999975\n",
      "Error: 0.004970250000003539 Prediction: 0.729499999999975\n",
      "Error: 0.004900000000003521 Prediction: 0.7299999999999749\n",
      "Error: 0.004830250000003504 Prediction: 0.7304999999999748\n",
      "Error: 0.004761000000003486 Prediction: 0.7309999999999748\n",
      "Error: 0.004692250000003469 Prediction: 0.7314999999999747\n",
      "Error: 0.004624000000003451 Prediction: 0.7319999999999747\n",
      "Error: 0.0045562500000034326 Prediction: 0.7324999999999746\n",
      "Error: 0.004489000000003415 Prediction: 0.7329999999999746\n",
      "Error: 0.0044222500000033966 Prediction: 0.7334999999999745\n",
      "Error: 0.004356000000003378 Prediction: 0.7339999999999745\n",
      "Error: 0.00429025000000336 Prediction: 0.7344999999999744\n",
      "Error: 0.0042250000000033415 Prediction: 0.7349999999999743\n",
      "Error: 0.004160250000003323 Prediction: 0.7354999999999743\n",
      "Error: 0.0040960000000033045 Prediction: 0.7359999999999742\n",
      "Error: 0.004032250000003285 Prediction: 0.7364999999999742\n",
      "Error: 0.003969000000003267 Prediction: 0.7369999999999741\n",
      "Error: 0.003906250000003247 Prediction: 0.7374999999999741\n",
      "Error: 0.003844000000003228 Prediction: 0.737999999999974\n",
      "Error: 0.003782250000003209 Prediction: 0.738499999999974\n",
      "Error: 0.0037210000000031896 Prediction: 0.7389999999999739\n",
      "Error: 0.00366025000000317 Prediction: 0.7394999999999738\n",
      "Error: 0.0036000000000031506 Prediction: 0.7399999999999738\n",
      "Error: 0.0035402500000031307 Prediction: 0.7404999999999737\n",
      "Error: 0.003481000000003111 Prediction: 0.7409999999999737\n",
      "Error: 0.0034222500000030912 Prediction: 0.7414999999999736\n",
      "Error: 0.003364000000003071 Prediction: 0.7419999999999736\n",
      "Error: 0.003306250000003051 Prediction: 0.7424999999999735\n",
      "Error: 0.0032490000000030307 Prediction: 0.7429999999999735\n",
      "Error: 0.0031922500000030104 Prediction: 0.7434999999999734\n",
      "Error: 0.0031360000000029897 Prediction: 0.7439999999999733\n",
      "Error: 0.003080250000002969 Prediction: 0.7444999999999733\n",
      "Error: 0.0030250000000029485 Prediction: 0.7449999999999732\n",
      "Error: 0.0029702500000029276 Prediction: 0.7454999999999732\n",
      "Error: 0.0029160000000029067 Prediction: 0.7459999999999731\n",
      "Error: 0.002862250000002886 Prediction: 0.7464999999999731\n",
      "Error: 0.0028090000000028648 Prediction: 0.746999999999973\n",
      "Error: 0.0027562500000028437 Prediction: 0.747499999999973\n",
      "Error: 0.002704000000002822 Prediction: 0.7479999999999729\n",
      "Error: 0.002652250000002801 Prediction: 0.7484999999999729\n",
      "Error: 0.002601000000002779 Prediction: 0.7489999999999728\n",
      "Error: 0.0025502500000027573 Prediction: 0.7494999999999727\n",
      "Error: 0.0025000000000027357 Prediction: 0.7499999999999727\n",
      "Error: 0.0024502500000027137 Prediction: 0.7504999999999726\n",
      "Error: 0.0024010000000026918 Prediction: 0.7509999999999726\n",
      "Error: 0.0023522500000026695 Prediction: 0.7514999999999725\n",
      "Error: 0.0023040000000026472 Prediction: 0.7519999999999725\n",
      "Error: 0.002256250000002625 Prediction: 0.7524999999999724\n",
      "Error: 0.0022090000000026025 Prediction: 0.7529999999999724\n",
      "Error: 0.00216225000000258 Prediction: 0.7534999999999723\n",
      "Error: 0.0021160000000025572 Prediction: 0.7539999999999722\n",
      "Error: 0.0020702500000025345 Prediction: 0.7544999999999722\n",
      "Error: 0.0020250000000025118 Prediction: 0.7549999999999721\n",
      "Error: 0.0019802500000024887 Prediction: 0.7554999999999721\n",
      "Error: 0.0019360000000024655 Prediction: 0.755999999999972\n",
      "Error: 0.0018922500000024423 Prediction: 0.756499999999972\n",
      "Error: 0.0018490000000024188 Prediction: 0.7569999999999719\n",
      "Error: 0.0018062500000023956 Prediction: 0.7574999999999719\n",
      "Error: 0.001764000000002372 Prediction: 0.7579999999999718\n",
      "Error: 0.0017222500000023482 Prediction: 0.7584999999999718\n",
      "Error: 0.0016810000000023245 Prediction: 0.7589999999999717\n",
      "Error: 0.0016402500000023007 Prediction: 0.7594999999999716\n",
      "Error: 0.0016000000000022767 Prediction: 0.7599999999999716\n",
      "Error: 0.0015602500000022525 Prediction: 0.7604999999999715\n",
      "Error: 0.0015210000000022283 Prediction: 0.7609999999999715\n",
      "Error: 0.001482250000002204 Prediction: 0.7614999999999714\n",
      "Error: 0.0014440000000021794 Prediction: 0.7619999999999714\n",
      "Error: 0.001406250000002155 Prediction: 0.7624999999999713\n",
      "Error: 0.0013690000000021302 Prediction: 0.7629999999999713\n",
      "Error: 0.0013322500000021056 Prediction: 0.7634999999999712\n",
      "Error: 0.0012960000000020806 Prediction: 0.7639999999999711\n",
      "Error: 0.0012602500000020557 Prediction: 0.7644999999999711\n",
      "Error: 0.0012250000000020305 Prediction: 0.764999999999971\n",
      "Error: 0.0011902500000020052 Prediction: 0.765499999999971\n",
      "Error: 0.00115600000000198 Prediction: 0.7659999999999709\n",
      "Error: 0.0011222500000019546 Prediction: 0.7664999999999709\n",
      "Error: 0.0010890000000019291 Prediction: 0.7669999999999708\n",
      "Error: 0.0010562500000019033 Prediction: 0.7674999999999708\n",
      "Error: 0.0010240000000018776 Prediction: 0.7679999999999707\n",
      "Error: 0.0009922500000018517 Prediction: 0.7684999999999707\n",
      "Error: 0.0009610000000018258 Prediction: 0.7689999999999706\n",
      "Error: 0.0009302500000017998 Prediction: 0.7694999999999705\n",
      "Error: 0.0009000000000017735 Prediction: 0.7699999999999705\n",
      "Error: 0.0008702500000017472 Prediction: 0.7704999999999704\n",
      "Error: 0.0008410000000017208 Prediction: 0.7709999999999704\n",
      "Error: 0.0008122500000016942 Prediction: 0.7714999999999703\n",
      "Error: 0.0007840000000016676 Prediction: 0.7719999999999703\n",
      "Error: 0.0007562500000016409 Prediction: 0.7724999999999702\n",
      "Error: 0.000729000000001614 Prediction: 0.7729999999999702\n",
      "Error: 0.000702250000001587 Prediction: 0.7734999999999701\n",
      "Error: 0.0006760000000015599 Prediction: 0.77399999999997\n",
      "Error: 0.0006502500000015327 Prediction: 0.77449999999997\n",
      "Error: 0.0006250000000015054 Prediction: 0.7749999999999699\n",
      "Error: 0.0006002500000014781 Prediction: 0.7754999999999699\n",
      "Error: 0.0005760000000014506 Prediction: 0.7759999999999698\n",
      "Error: 0.0005522500000014229 Prediction: 0.7764999999999698\n",
      "Error: 0.0005290000000013951 Prediction: 0.7769999999999697\n",
      "Error: 0.0005062500000013673 Prediction: 0.7774999999999697\n",
      "Error: 0.00048400000000133937 Prediction: 0.7779999999999696\n",
      "Error: 0.0004622500000013113 Prediction: 0.7784999999999695\n",
      "Error: 0.0004410000000012831 Prediction: 0.7789999999999695\n",
      "Error: 0.0004202500000012548 Prediction: 0.7794999999999694\n",
      "Error: 0.0004000000000012264 Prediction: 0.7799999999999694\n",
      "Error: 0.0003802500000011979 Prediction: 0.7804999999999693\n",
      "Error: 0.00036100000000116925 Prediction: 0.7809999999999693\n",
      "Error: 0.0003422500000011405 Prediction: 0.7814999999999692\n",
      "Error: 0.0003240000000011117 Prediction: 0.7819999999999692\n",
      "Error: 0.00030625000000108273 Prediction: 0.7824999999999691\n",
      "Error: 0.00028900000000105366 Prediction: 0.782999999999969\n",
      "Error: 0.0002722500000010245 Prediction: 0.783499999999969\n",
      "Error: 0.00025600000000099523 Prediction: 0.7839999999999689\n",
      "Error: 0.00024025000000096582 Prediction: 0.7844999999999689\n",
      "Error: 0.0002250000000009363 Prediction: 0.7849999999999688\n",
      "Error: 0.0002102500000009067 Prediction: 0.7854999999999688\n",
      "Error: 0.00019600000000087698 Prediction: 0.7859999999999687\n",
      "Error: 0.00018225000000084715 Prediction: 0.7864999999999687\n",
      "Error: 0.0001690000000008172 Prediction: 0.7869999999999686\n",
      "Error: 0.00015625000000078716 Prediction: 0.7874999999999686\n",
      "Error: 0.000144000000000757 Prediction: 0.7879999999999685\n",
      "Error: 0.0001322500000007267 Prediction: 0.7884999999999684\n",
      "Error: 0.00012100000000069633 Prediction: 0.7889999999999684\n",
      "Error: 0.00011025000000066583 Prediction: 0.7894999999999683\n",
      "Error: 0.00010000000000063523 Prediction: 0.7899999999999683\n",
      "Error: 9.025000000060451e-05 Prediction: 0.7904999999999682\n",
      "Error: 8.100000000057368e-05 Prediction: 0.7909999999999682\n",
      "Error: 7.225000000054275e-05 Prediction: 0.7914999999999681\n",
      "Error: 6.40000000005117e-05 Prediction: 0.7919999999999681\n",
      "Error: 5.625000000048055e-05 Prediction: 0.792499999999968\n",
      "Error: 4.9000000000449285e-05 Prediction: 0.792999999999968\n",
      "Error: 4.225000000041791e-05 Prediction: 0.7934999999999679\n",
      "Error: 3.6000000000386424e-05 Prediction: 0.7939999999999678\n",
      "Error: 3.0250000000354826e-05 Prediction: 0.7944999999999678\n",
      "Error: 2.500000000032312e-05 Prediction: 0.7949999999999677\n",
      "Error: 2.0250000000291302e-05 Prediction: 0.7954999999999677\n",
      "Error: 1.6000000000259378e-05 Prediction: 0.7959999999999676\n",
      "Error: 1.225000000022734e-05 Prediction: 0.7964999999999676\n",
      "Error: 9.000000000195194e-06 Prediction: 0.7969999999999675\n",
      "Error: 6.250000000162936e-06 Prediction: 0.7974999999999675\n",
      "Error: 4.000000000130569e-06 Prediction: 0.7979999999999674\n",
      "Error: 2.2500000000980924e-06 Prediction: 0.7984999999999673\n",
      "Error: 1.000000000065505e-06 Prediction: 0.7989999999999673\n",
      "Error: 2.5000000003280753e-07 Prediction: 0.7994999999999672\n",
      "Error: 1.0799505792475652e-27 Prediction: 0.7999999999999672\n"
     ]
    }
   ],
   "source": [
    "# Hot and Cold Learning\n",
    "weight = 0.5\n",
    "input = 0.5\n",
    "goal_prediction = 0.8\n",
    "\n",
    "step_amount = 0.001\n",
    "\n",
    "for iterration in range(1101):\n",
    "    \n",
    "    prediction = input * weight\n",
    "    error = (prediction - goal_prediction) ** 2\n",
    "    \n",
    "    print(\"Error: \" + str(error) + \" Prediction: \" + str(prediction))\n",
    "    \n",
    "    up_prediction = input * (weight + step_amount)\n",
    "    up_error = (goal_prediction - up_prediction) ** 2\n",
    "    \n",
    "    down_prediction = input * (weight - step_amount)\n",
    "    down_error = (goal_prediction - down_prediction) ** 2\n",
    "    \n",
    "    if (down_error < up_error):\n",
    "        weight = weight - step_amount\n",
    "        \n",
    "    if (down_error > up_error):\n",
    "        weight = weight + step_amount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.30250000000000005 Direction and amount: -0.275 Prediction: 0.25\n",
      "Error: 0.17015625000000004 Direction and amount: -0.20625000000000002 Prediction: 0.3875\n",
      "Error: 0.095712890625 Direction and amount: -0.1546875 Prediction: 0.49062500000000003\n",
      "Error: 0.05383850097656251 Direction and amount: -0.11601562500000001 Prediction: 0.56796875\n",
      "Error: 0.03028415679931642 Direction and amount: -0.08701171875000002 Prediction: 0.6259765625\n",
      "Error: 0.0170348381996155 Direction and amount: -0.06525878906250004 Prediction: 0.669482421875\n",
      "Error: 0.00958209648728372 Direction and amount: -0.04894409179687503 Prediction: 0.70211181640625\n",
      "Error: 0.005389929274097089 Direction and amount: -0.03670806884765626 Prediction: 0.7265838623046875\n",
      "Error: 0.0030318352166796153 Direction and amount: -0.02753105163574221 Prediction: 0.7449378967285156\n",
      "Error: 0.0017054073093822882 Direction and amount: -0.020648288726806685 Prediction: 0.7587034225463867\n",
      "Error: 0.0009592916115275371 Direction and amount: -0.015486216545105014 Prediction: 0.76902756690979\n",
      "Error: 0.0005396015314842384 Direction and amount: -0.011614662408828746 Prediction: 0.7767706751823426\n",
      "Error: 0.000303525861459885 Direction and amount: -0.008710996806621574 Prediction: 0.7825780063867569\n",
      "Error: 0.00017073329707118678 Direction and amount: -0.006533247604966208 Prediction: 0.7869335047900676\n",
      "Error: 9.603747960254256e-05 Direction and amount: -0.004899935703724656 Prediction: 0.7902001285925507\n",
      "Error: 5.402108227642978e-05 Direction and amount: -0.003674951777793478 Prediction: 0.7926500964444131\n",
      "Error: 3.038685878049206e-05 Direction and amount: -0.0027562138333451225 Prediction: 0.7944875723333098\n",
      "Error: 1.7092608064027242e-05 Direction and amount: -0.0020671603750088696 Prediction: 0.7958656792499823\n",
      "Error: 9.614592036015323e-06 Direction and amount: -0.0015503702812566522 Prediction: 0.7968992594374867\n",
      "Error: 5.408208020258491e-06 Direction and amount: -0.0011627777109424753 Prediction: 0.7976744445781151\n"
     ]
    }
   ],
   "source": [
    "# Calculating both direction and amount from error\n",
    "# This is gradient descent!\n",
    "\n",
    "weight = 0.5\n",
    "goal_pred = 0.8\n",
    "input = 0.5\n",
    "\n",
    "for iteration in range(20):\n",
    "    pred = input * weight\n",
    "    error = (pred - goal_pred) ** 2\n",
    "    # pure error * scaling, negative reversal and stopping\n",
    "    direction_and_amount = (pred - goal_pred) * input\n",
    "    weight = weight - direction_and_amount\n",
    "    \n",
    "    print(\"Error: \" + str(error) + \" Direction and amount: \" + str(direction_and_amount) + \" Prediction: \" + str(pred))\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One iteration of gradient\n",
    "**This performs a weight update on a single training example (input->True) pair**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.An empty network\n",
    "weight = 0.1\n",
    "alpha = 0.01\n",
    "\n",
    "def neural_network(input, weight):\n",
    "    prediction = input * weight\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2. PREDICT: Making a prediction and evaluating error\n",
    "number_of_toes = [8.5]\n",
    "win_or_lose_binary = [1] # won!\n",
    "\n",
    "input = number_of_toes[0]\n",
    "goal_pred = win_or_lose_binary[0]\n",
    "\n",
    "pred = neural_network(input, weight)\n",
    "\n",
    "error = (pred - goal_pred) ** 2 #MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3. COMPARE: Calculating \"Node Delta\" and Putting it on the Output Node\n",
    "delta = pred - goal_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delta is a measurement of \"how much this node missed\". Thus, since the true prediction was 1.0 and our networks prediction was 0.85, the network was too **low** by 0.15. Thus delta is **negative** 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   The primary difference between the gradient descent in previous code block and the implementation here just happened. The delta is a new variable. It is the \"raw amount that the node was too high or too low\". Instead of cumpouting direction_and_amount directly, we first calculate how much we wanted our output node to be different. Only then do we compute our direction_and_amount to change the weight (\"weight_delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. LEARN: Calculating \"Weight Delta\" and Putting it on the Weight\n",
    "weight_delta = input * delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight delta is a measure of \"how much this weight caused the network to miss\". We calculate it by multiplying the weights output \"Node Delta\" by the weights input. Thus we create each \"Weight Delta\" by scaling its output \"Node Delta\" by the weights input.\n",
    "This accounts for the 3 aforementioned properties of our \"direction_and_amount\" - scaling, negative reversal and stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5. LEARN: Update the Weight\n",
    "weight -= weight_delta * alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We multiply our weight_delta by a small number \"alpha\" before using it to update our weight. This allows us to control how fast the network learns. If it learns too fast, it can update weights too agressively and overshoot. More on this later. Note that the weight update made the same change (small increase) as Hot and Cold learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Is Just Reducing Error\n",
    "### Modifying weight to reduce our error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Error:0.30250000000000005\n",
      "Delta:-0.55\n",
      "Weight Delta:-0.275\n",
      "Prediction:0.25\n",
      "Updated weight:0.775\n",
      "--------------------\n",
      "Error:0.17015625000000004\n",
      "Delta:-0.41250000000000003\n",
      "Weight Delta:-0.20625000000000002\n",
      "Prediction:0.3875\n",
      "Updated weight:0.9812500000000001\n",
      "--------------------\n",
      "Error:0.095712890625\n",
      "Delta:-0.309375\n",
      "Weight Delta:-0.1546875\n",
      "Prediction:0.49062500000000003\n",
      "Updated weight:1.1359375\n",
      "--------------------\n",
      "Error:0.05383850097656251\n",
      "Delta:-0.23203125000000002\n",
      "Weight Delta:-0.11601562500000001\n",
      "Prediction:0.56796875\n",
      "Updated weight:1.251953125\n",
      "--------------------\n",
      "Error:0.03028415679931642\n",
      "Delta:-0.17402343750000004\n",
      "Weight Delta:-0.08701171875000002\n",
      "Prediction:0.6259765625\n",
      "Updated weight:1.33896484375\n",
      "--------------------\n",
      "Error:0.0170348381996155\n",
      "Delta:-0.1305175781250001\n",
      "Weight Delta:-0.06525878906250004\n",
      "Prediction:0.669482421875\n",
      "Updated weight:1.4042236328125\n",
      "--------------------\n",
      "Error:0.00958209648728372\n",
      "Delta:-0.09788818359375007\n",
      "Weight Delta:-0.04894409179687503\n",
      "Prediction:0.70211181640625\n",
      "Updated weight:1.453167724609375\n",
      "--------------------\n",
      "Error:0.005389929274097089\n",
      "Delta:-0.07341613769531252\n",
      "Weight Delta:-0.03670806884765626\n",
      "Prediction:0.7265838623046875\n",
      "Updated weight:1.4898757934570312\n",
      "--------------------\n",
      "Error:0.0030318352166796153\n",
      "Delta:-0.05506210327148442\n",
      "Weight Delta:-0.02753105163574221\n",
      "Prediction:0.7449378967285156\n",
      "Updated weight:1.5174068450927733\n",
      "--------------------\n",
      "Error:0.0017054073093822882\n",
      "Delta:-0.04129657745361337\n",
      "Weight Delta:-0.020648288726806685\n",
      "Prediction:0.7587034225463867\n",
      "Updated weight:1.53805513381958\n",
      "--------------------\n",
      "Error:0.0009592916115275371\n",
      "Delta:-0.030972433090210028\n",
      "Weight Delta:-0.015486216545105014\n",
      "Prediction:0.76902756690979\n",
      "Updated weight:1.553541350364685\n",
      "--------------------\n",
      "Error:0.0005396015314842384\n",
      "Delta:-0.023229324817657493\n",
      "Weight Delta:-0.011614662408828746\n",
      "Prediction:0.7767706751823426\n",
      "Updated weight:1.5651560127735138\n",
      "--------------------\n",
      "Error:0.000303525861459885\n",
      "Delta:-0.017421993613243147\n",
      "Weight Delta:-0.008710996806621574\n",
      "Prediction:0.7825780063867569\n",
      "Updated weight:1.5738670095801353\n",
      "--------------------\n",
      "Error:0.00017073329707118678\n",
      "Delta:-0.013066495209932416\n",
      "Weight Delta:-0.006533247604966208\n",
      "Prediction:0.7869335047900676\n",
      "Updated weight:1.5804002571851015\n",
      "--------------------\n",
      "Error:9.603747960254256e-05\n",
      "Delta:-0.009799871407449312\n",
      "Weight Delta:-0.004899935703724656\n",
      "Prediction:0.7902001285925507\n",
      "Updated weight:1.5853001928888262\n",
      "--------------------\n",
      "Error:5.402108227642978e-05\n",
      "Delta:-0.007349903555586956\n",
      "Weight Delta:-0.003674951777793478\n",
      "Prediction:0.7926500964444131\n",
      "Updated weight:1.5889751446666196\n",
      "--------------------\n",
      "Error:3.038685878049206e-05\n",
      "Delta:-0.005512427666690245\n",
      "Weight Delta:-0.0027562138333451225\n",
      "Prediction:0.7944875723333098\n",
      "Updated weight:1.5917313584999646\n",
      "--------------------\n",
      "Error:1.7092608064027242e-05\n",
      "Delta:-0.004134320750017739\n",
      "Weight Delta:-0.0020671603750088696\n",
      "Prediction:0.7958656792499823\n",
      "Updated weight:1.5937985188749735\n",
      "--------------------\n",
      "Error:9.614592036015323e-06\n",
      "Delta:-0.0031007405625133044\n",
      "Weight Delta:-0.0015503702812566522\n",
      "Prediction:0.7968992594374867\n",
      "Updated weight:1.5953488891562302\n",
      "--------------------\n",
      "Error:5.408208020258491e-06\n",
      "Delta:-0.0023255554218849506\n",
      "Weight Delta:-0.0011627777109424753\n",
      "Prediction:0.7976744445781151\n",
      "Updated weight:1.5965116668671726\n"
     ]
    }
   ],
   "source": [
    "weight = 0.5\n",
    "goal_pred = 0.8\n",
    "input = 0.5\n",
    "\n",
    "for iteration in range(20):\n",
    "    # The following 2 lines have a secret:\n",
    "    pred = input * weight # Line 1\n",
    "    error = (pred - goal_pred) ** 2 # Line 2\n",
    "    delta = pred - goal_pred\n",
    "    weight_delta  = delta * input\n",
    "    weight = weight - weight_delta\n",
    "    \n",
    "    print(\"--------------------\")\n",
    "    print(\"Error:\" + str(error))\n",
    "    print(\"Delta:\" + str(delta))\n",
    "    print(\"Weight Delta:\" + str(weight_delta))\n",
    "    print(\"Prediction:\" + str(pred))\n",
    "    print(\"Updated weight:\" + str(weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Golden Method for Learning\n",
    "Adjusting each **weight** in the correct **direction** and by correct **amount** so that our **error** reduces to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we are trying to do is figure out the right direction and amount to midfy weight so that our error goes down. The secret to this lies in our pred and error calculations. Notice that we actually use our pred inside the error calculation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Secret\n",
    "For any **input** and **goal_pred** there is an exact relationship defined between our error and knob_weight, found by combining our prediction and error formulas. In this case:\n",
    "```error = ((0.5 * weight) - 0.8 ** 2```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Several stop of Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Prediction:0.0\n",
      "Error:0.6400000000000001\n",
      "Delta:-0.8\n",
      "Weight Delta:-0.8800000000000001\n",
      "Updated weight:0.8800000000000001\n",
      "--------------------\n",
      "Prediction:0.9680000000000002\n",
      "Error:0.02822400000000005\n",
      "Delta:0.16800000000000015\n",
      "Weight Delta:0.1848000000000002\n",
      "Updated weight:0.6951999999999999\n",
      "--------------------\n",
      "Prediction:0.76472\n",
      "Error:0.0012446784000000064\n",
      "Delta:-0.03528000000000009\n",
      "Weight Delta:-0.0388080000000001\n",
      "Updated weight:0.734008\n",
      "--------------------\n",
      "Prediction:0.8074088\n",
      "Error:5.4890317439999896e-05\n",
      "Delta:0.007408799999999993\n",
      "Weight Delta:0.008149679999999992\n",
      "Updated weight:0.72585832\n"
     ]
    }
   ],
   "source": [
    "weight = 0.0\n",
    "goal_pred = 0.8\n",
    "input = 1.1\n",
    "\n",
    "for iteration in range(4):\n",
    "    pred = input * weight\n",
    "    error = (pred - goal_pred) ** 2\n",
    "    delta = (pred - goal_pred)\n",
    "    weight_delta = delta * input\n",
    "    weight = weight - weight_delta\n",
    "    \n",
    "    print(\"--------------------\")\n",
    "    print(\"Prediction:\" + str(pred))\n",
    "    print(\"Error:\" + str(error))\n",
    "    print(\"Delta:\" + str(delta))\n",
    "    print(\"Weight Delta:\" + str(weight_delta))\n",
    "    print(\"Updated weight:\" + str(weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunnel Vision on  One Concept\n",
    "## Concept: \"Learning is adjusting our weight to reduce the error to zero\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error = ((input * weight) - goal_pred) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we use this formula to know how to change our *weight* so that our *error*\n",
    "moves in a **particular** direction? Now **THAT** is the right question!\n",
    "\n",
    "This formula is the exact relationship between these two variables, and now we're going to figure out how to change one variable so that we move the other variable in a *particular* direction.\n",
    "\n",
    "Given a function, the **derivative** represents the *direction* and the *amount* that one variable changes if you change the other variable! If derivative is explained like *\"the slope at a point on a line or curve\"* then the slope's sign gives us **direction** and the slope's steepness gives us **amount**. We can use both of these to thelp find the goal weight!\n",
    "\n",
    "## With derivatives we can pick any two variables in any formula and know how they interact!\n",
    "** For any function we can learn how to change one variable so that we can move another variable in a direction! It is important you know this in your bones! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Prediction:2.0\n",
      "Error:1.44\n",
      "Delta:1.2\n",
      "Weight Delta:2.4\n",
      "Updated weight:-1.4\n",
      "--------------------\n",
      "Prediction:-2.8\n",
      "Error:12.959999999999997\n",
      "Delta:-3.5999999999999996\n",
      "Weight Delta:-7.199999999999999\n",
      "Updated weight:5.799999999999999\n",
      "--------------------\n",
      "Prediction:11.599999999999998\n",
      "Error:116.63999999999994\n",
      "Delta:10.799999999999997\n",
      "Weight Delta:21.599999999999994\n",
      "Updated weight:-15.799999999999995\n",
      "--------------------\n",
      "Prediction:-31.59999999999999\n",
      "Error:1049.7599999999995\n",
      "Delta:-32.39999999999999\n",
      "Weight Delta:-64.79999999999998\n",
      "Updated weight:48.999999999999986\n",
      "--------------------\n",
      "Prediction:97.99999999999997\n",
      "Error:9447.839999999995\n",
      "Delta:97.19999999999997\n",
      "Weight Delta:194.39999999999995\n",
      "Updated weight:-145.39999999999998\n",
      "--------------------\n",
      "Prediction:-290.79999999999995\n",
      "Error:85030.55999999998\n",
      "Delta:-291.59999999999997\n",
      "Weight Delta:-583.1999999999999\n",
      "Updated weight:437.79999999999995\n",
      "--------------------\n",
      "Prediction:875.5999999999999\n",
      "Error:765275.0399999999\n",
      "Delta:874.8\n",
      "Weight Delta:1749.6\n",
      "Updated weight:-1311.8\n",
      "--------------------\n",
      "Prediction:-2623.6\n",
      "Error:6887475.36\n",
      "Delta:-2624.4\n",
      "Weight Delta:-5248.8\n",
      "Updated weight:3937.0\n",
      "--------------------\n",
      "Prediction:7874.0\n",
      "Error:61987278.239999995\n",
      "Delta:7873.2\n",
      "Weight Delta:15746.4\n",
      "Updated weight:-11809.4\n",
      "--------------------\n",
      "Prediction:-23618.8\n",
      "Error:557885504.16\n",
      "Delta:-23619.6\n",
      "Weight Delta:-47239.2\n",
      "Updated weight:35429.799999999996\n",
      "--------------------\n",
      "Prediction:70859.59999999999\n",
      "Error:5020969537.439999\n",
      "Delta:70858.79999999999\n",
      "Weight Delta:141717.59999999998\n",
      "Updated weight:-106287.79999999999\n",
      "--------------------\n",
      "Prediction:-212575.59999999998\n",
      "Error:45188725836.959984\n",
      "Delta:-212576.39999999997\n",
      "Weight Delta:-425152.79999999993\n",
      "Updated weight:318864.99999999994\n",
      "--------------------\n",
      "Prediction:637729.9999999999\n",
      "Error:406698532532.6398\n",
      "Delta:637729.1999999998\n",
      "Weight Delta:1275458.3999999997\n",
      "Updated weight:-956593.3999999997\n",
      "--------------------\n",
      "Prediction:-1913186.7999999993\n",
      "Error:3660286792793.758\n",
      "Delta:-1913187.5999999994\n",
      "Weight Delta:-3826375.199999999\n",
      "Updated weight:2869781.799999999\n",
      "--------------------\n",
      "Prediction:5739563.599999998\n",
      "Error:32942581135143.816\n",
      "Delta:5739562.799999998\n",
      "Weight Delta:11479125.599999996\n",
      "Updated weight:-8609343.799999997\n",
      "--------------------\n",
      "Prediction:-17218687.599999994\n",
      "Error:296483230216294.4\n",
      "Delta:-17218688.399999995\n",
      "Weight Delta:-34437376.79999999\n",
      "Updated weight:25828032.999999993\n",
      "--------------------\n",
      "Prediction:51656065.999999985\n",
      "Error:2668349071946650.0\n",
      "Delta:51656065.19999999\n",
      "Weight Delta:103312130.39999998\n",
      "Updated weight:-77484097.39999998\n",
      "--------------------\n",
      "Prediction:-154968194.79999995\n",
      "Error:2.401514164751985e+16\n",
      "Delta:-154968195.59999996\n",
      "Weight Delta:-309936391.1999999\n",
      "Updated weight:232452293.79999995\n",
      "--------------------\n",
      "Prediction:464904587.5999999\n",
      "Error:2.1613627482767862e+17\n",
      "Delta:464904586.7999999\n",
      "Weight Delta:929809173.5999998\n",
      "Updated weight:-697356879.7999998\n",
      "--------------------\n",
      "Prediction:-1394713759.5999997\n",
      "Error:1.9452264734491075e+18\n",
      "Delta:-1394713760.3999996\n",
      "Weight Delta:-2789427520.799999\n",
      "Updated weight:2092070640.9999995\n"
     ]
    }
   ],
   "source": [
    "# This thing introduces divergence - we overcorrect way too much\n",
    "weight = 1.0\n",
    "goal_pred = 0.8\n",
    "input = 2\n",
    "\n",
    "for iteration in range(20):\n",
    "    pred = input * weight\n",
    "    error = (pred - goal_pred) ** 2\n",
    "    delta = (pred - goal_pred)\n",
    "    weight_delta = delta * input\n",
    "    weight = weight - weight_delta\n",
    "    \n",
    "    print(\"--------------------\")\n",
    "    print(\"Prediction:\" + str(pred))\n",
    "    print(\"Error:\" + str(error))\n",
    "    print(\"Delta:\" + str(delta))\n",
    "    print(\"Weight Delta:\" + str(weight_delta))\n",
    "    print(\"Updated weight:\" + str(weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter the Alpha\n",
    "`weight = weight - (alpha * derivative)`\n",
    "\n",
    "instead of \n",
    "\n",
    "`weight = weight - derivate`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Prediction:2.0\n",
      "Error:1.44\n",
      "Delta:1.2\n",
      "Weight Delta:2.4\n",
      "Updated weight:0.76\n",
      "--------------------\n",
      "Prediction:1.52\n",
      "Error:0.5184\n",
      "Delta:0.72\n",
      "Weight Delta:1.44\n",
      "Updated weight:0.616\n",
      "--------------------\n",
      "Prediction:1.232\n",
      "Error:0.18662399999999996\n",
      "Delta:0.43199999999999994\n",
      "Weight Delta:0.8639999999999999\n",
      "Updated weight:0.5296\n",
      "--------------------\n",
      "Prediction:1.0592\n",
      "Error:0.06718463999999993\n",
      "Delta:0.2591999999999999\n",
      "Weight Delta:0.5183999999999997\n",
      "Updated weight:0.47775999999999996\n",
      "--------------------\n",
      "Prediction:0.9555199999999999\n",
      "Error:0.024186470399999962\n",
      "Delta:0.15551999999999988\n",
      "Weight Delta:0.31103999999999976\n",
      "Updated weight:0.446656\n",
      "--------------------\n",
      "Prediction:0.893312\n",
      "Error:0.008707129343999991\n",
      "Delta:0.09331199999999995\n",
      "Weight Delta:0.1866239999999999\n",
      "Updated weight:0.42799360000000003\n",
      "--------------------\n",
      "Prediction:0.8559872000000001\n",
      "Error:0.0031345665638400017\n",
      "Delta:0.055987200000000015\n",
      "Weight Delta:0.11197440000000003\n",
      "Updated weight:0.41679616\n",
      "--------------------\n",
      "Prediction:0.83359232\n",
      "Error:0.0011284439629824007\n",
      "Delta:0.03359232000000001\n",
      "Weight Delta:0.06718464000000002\n",
      "Updated weight:0.41007769600000005\n",
      "--------------------\n",
      "Prediction:0.8201553920000001\n",
      "Error:0.000406239826673666\n",
      "Delta:0.02015539200000005\n",
      "Weight Delta:0.0403107840000001\n",
      "Updated weight:0.40604661760000005\n",
      "--------------------\n",
      "Prediction:0.8120932352000001\n",
      "Error:0.0001462463376025203\n",
      "Delta:0.012093235200000052\n",
      "Weight Delta:0.024186470400000104\n",
      "Updated weight:0.40362797056000005\n",
      "--------------------\n",
      "Prediction:0.8072559411200001\n",
      "Error:5.264868153690763e-05\n",
      "Delta:0.007255941120000053\n",
      "Weight Delta:0.014511882240000107\n",
      "Updated weight:0.402176782336\n",
      "--------------------\n",
      "Prediction:0.804353564672\n",
      "Error:1.895352535328636e-05\n",
      "Delta:0.004353564671999988\n",
      "Weight Delta:0.008707129343999975\n",
      "Updated weight:0.4013060694016\n",
      "--------------------\n",
      "Prediction:0.8026121388032\n",
      "Error:6.8232691271830894e-06\n",
      "Delta:0.0026121388031999926\n",
      "Weight Delta:0.005224277606399985\n",
      "Updated weight:0.40078364164096003\n",
      "--------------------\n",
      "Prediction:0.8015672832819201\n",
      "Error:2.456376885785982e-06\n",
      "Delta:0.0015672832819200178\n",
      "Weight Delta:0.0031345665638400355\n",
      "Updated weight:0.40047018498457604\n",
      "--------------------\n",
      "Prediction:0.8009403699691521\n",
      "Error:8.842956788829953e-07\n",
      "Delta:0.0009403699691520329\n",
      "Weight Delta:0.0018807399383040657\n",
      "Updated weight:0.4002821109907456\n",
      "--------------------\n",
      "Prediction:0.8005642219814912\n",
      "Error:3.1834644439785323e-07\n",
      "Delta:0.0005642219814911975\n",
      "Weight Delta:0.001128443962982395\n",
      "Updated weight:0.4001692665944474\n",
      "--------------------\n",
      "Prediction:0.8003385331888948\n",
      "Error:1.1460471998325723e-07\n",
      "Delta:0.0003385331888947629\n",
      "Weight Delta:0.0006770663777895258\n",
      "Updated weight:0.40010155995666846\n",
      "--------------------\n",
      "Prediction:0.8002031199133369\n",
      "Error:4.125769919398162e-08\n",
      "Delta:0.00020311991333687995\n",
      "Weight Delta:0.0004062398266737599\n",
      "Updated weight:0.4000609359740011\n",
      "--------------------\n",
      "Prediction:0.8001218719480022\n",
      "Error:1.485277170984421e-08\n",
      "Delta:0.00012187194800217238\n",
      "Weight Delta:0.00024374389600434476\n",
      "Updated weight:0.40003656158440065\n",
      "--------------------\n",
      "Prediction:0.8000731231688013\n",
      "Error:5.346997815537421e-09\n",
      "Delta:7.312316880125902e-05\n",
      "Weight Delta:0.00014624633760251804\n",
      "Updated weight:0.4000219369506404\n"
     ]
    }
   ],
   "source": [
    "# This thing introduces divergence - we overcorrect way too much\n",
    "weight = 1.0\n",
    "goal_pred = 0.8\n",
    "input = 2\n",
    "alpha = 0.1\n",
    "\n",
    "for iteration in range(20):\n",
    "    pred = input * weight\n",
    "    error = (pred - goal_pred) ** 2\n",
    "    delta = (pred - goal_pred)\n",
    "    weight_delta = delta * input\n",
    "    weight = weight - (weight_delta * alpha)\n",
    "    \n",
    "    print(\"--------------------\")\n",
    "    print(\"Prediction:\" + str(pred))\n",
    "    print(\"Error:\" + str(error))\n",
    "    print(\"Delta:\" + str(delta))\n",
    "    print(\"Weight Delta:\" + str(weight_delta))\n",
    "    print(\"Updated weight:\" + str(weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# DELTA\n",
    "A measure of how much we want a node's value to be higher or lower to predict \"perfectly\" given the current training example.\n",
    "\n",
    "**weight_delta** on the other hand, is an estimate for the direction and amount we should move our *weights* to reduce our *node delta*, inferred by the *derivative*. How do we transform our delta into a weight_delta? We multiply delta by a weight's input.\n",
    "\n",
    "\n",
    "### Several steps of Learning:\n",
    "\n",
    "How about not updating one weight?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Pred: 0.8600000000000001\n",
      "Error: 0.01959999999999997\n",
      "Delta: -0.1399999999999999\n",
      "Weights: [0.1, 0.2, -0.1]\n",
      "Weight deltas: [0, -0.09099999999999994, -0.16799999999999987]\n",
      "-------------------\n",
      "Iteration 2\n",
      "Pred: 0.9642999999999999\n",
      "Error: 0.0012744900000000046\n",
      "Delta: -0.035700000000000065\n",
      "Weights: [0.1, 0.2364, -0.03280000000000005]\n",
      "Weight deltas: [0, -0.02320500000000004, -0.04284000000000008]\n",
      "-------------------\n",
      "Iteration 3\n",
      "Pred: 0.9908965000000001\n",
      "Error: 8.287371224999874e-05\n",
      "Delta: -0.009103499999999931\n",
      "Weights: [0.1, 0.245682, -0.015664000000000018]\n",
      "Weight deltas: [0, -0.005917274999999955, -0.010924199999999917]\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "def neural_network(input, weights):\n",
    "    out = 0\n",
    "    for i in range(len(input)):\n",
    "        out += (input[i] * weights[i])\n",
    "    return out\n",
    "\n",
    "def ele_mul(scalar, vector):\n",
    "    out = [0, 0, 0]\n",
    "    for i in range(len(out)):\n",
    "        out[i] = vector[i] * scalar\n",
    "    return out\n",
    "\n",
    "toes = [8.5, 9.4, 9.9, 9.0]\n",
    "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "\n",
    "win_or_lose_binary = [1, 1, 0 , 1]\n",
    "true = win_or_lose_binary[0]\n",
    "\n",
    "alpha = 0.4\n",
    "weights = [0.1, 0.2, -0.1]\n",
    "inputs = [toes[0], wlrec[0], nfans[0]]\n",
    "\n",
    "for iter in range(3):\n",
    "    pred = neural_network(inputs, weights)\n",
    "    \n",
    "    error = (pred - true) ** 2\n",
    "    delta = pred - true\n",
    "    \n",
    "    weight_deltas = ele_mul(delta, inputs)\n",
    "    weight_deltas[0] = 0\n",
    "    \n",
    "    print(\"Iteration {}\".format(iter+1))\n",
    "    print(\"Pred: {}\".format(pred))\n",
    "    print(\"Error: {}\".format(error))\n",
    "    print(\"Delta: {}\".format(delta))\n",
    "    print(\"Weights: {}\".format(weights))\n",
    "    print(\"Weight deltas: {}\".format(weight_deltas))\n",
    "    print(\"-------------------\")\n",
    "    \n",
    "    for i in range(len(weights)):\n",
    "        weights[i] -= alpha * weight_deltas[i]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out, as the error is shared, when one weight finds the \"bottom of the bowl\", all of the weights have found it. Now consider a network with multiple outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: [0.27, 0.18000000000000002, 0.81]\n",
      "Error: [0.028900000000000006, 0.6723999999999999, 0.5041000000000001]\n",
      "Delta: [0.17, -0.82, 0.7100000000000001]\n",
      "Weights: [0.3, 0.2, 0.9]\n",
      "Weight deltas: [0.15300000000000002, -0.738, 0.6390000000000001]\n",
      "-------------------\n",
      "Pred: [0.20115, 0.5121, 0.5224500000000001]\n",
      "Error: [0.010231322499999997, 0.23804641, 0.17846400250000008]\n",
      "Delta: [0.17, -0.82, 0.7100000000000001]\n",
      "Weights: [0.22349999999999998, 0.569, 0.5805]\n",
      "Weight deltas: [0.09103499999999999, -0.43911, 0.3802050000000001]\n",
      "-------------------\n",
      "Pred: [0.16018425, 0.7096994999999999, 0.35135774999999997]\n",
      "Error: [0.0036221439480624996, 0.08427438030025004, 0.06318071848506247]\n",
      "Delta: [0.17, -0.82, 0.7100000000000001]\n",
      "Weights: [0.1779825, 0.7885549999999999, 0.39039749999999995]\n",
      "Weight deltas: [0.054165824999999994, -0.2612704500000001, 0.22622197499999994]\n",
      "-------------------\n",
      "Pred: [0.13580962875, 0.8272712025, 0.24955786124999998]\n",
      "Error: [0.0012823295112128258, 0.02983523748579602, 0.022367553861674244]\n",
      "Delta: [0.17, -0.82, 0.7100000000000001]\n",
      "Weights: [0.1508995875, 0.9191902249999999, 0.27728651249999997]\n",
      "Weight deltas: [0.03222866587499999, -0.15545591775000003, 0.134602075125]\n",
      "-------------------\n",
      "Pred: [0.12130672910624998, 0.8972263654875, 0.18898692744374998]\n",
      "Error: [0.00045397670520711995, 0.01056241995090893, 0.007918673255879222]\n",
      "Delta: [0.17, -0.82, 0.7100000000000001]\n",
      "Weights: [0.13478525456249998, 0.996918183875, 0.20998547493749997]\n",
      "Weight deltas: [0.019176056195624982, -0.09249627106125, 0.08008823469937498]\n",
      "-------------------\n",
      "Pred: [0.11267750381821875, 0.9388496874650624, 0.15294722182903123]\n",
      "Error: [0.00016071910306095097, 0.0037393607231205506, 0.0028034082994126404]\n",
      "Delta: [0.17, -0.82, 0.7100000000000001]\n",
      "Weights: [0.1251972264646875, 1.0431663194056249, 0.16994135758781248]\n",
      "Weight deltas: [0.011409753436396875, -0.055035281281443874, 0.0476524996461281]\n",
      "-------------------\n",
      "Pred: [0.10754311477184016, 0.9636155640417122, 0.13150359698827357]\n",
      "Error: [5.689858046115309e-05, 0.0013238271800027446, 0.0009924766231995594]\n",
      "Delta: [0.17, -0.82, 0.7100000000000001]\n",
      "Weights: [0.11949234974648906, 1.070683960046347, 0.14611510776474843]\n",
      "Weight deltas: [0.006788803294656136, -0.032745992362459, 0.028353237289446213]\n",
      "-------------------\n",
      "Pred: [0.10448815328924489, 0.9783512606048188, 0.11874464020802279]\n",
      "Error: [2.0143519947759696e-05, 0.0004686679174004702, 0.00035136153652822453]\n",
      "Delta: [0.17, -0.82, 0.7100000000000001]\n",
      "Weights: [0.11609794809916099, 1.0870569562275765, 0.13193848912002532]\n",
      "Weight deltas: [0.004039337960320398, -0.019483865455663076, 0.016870176187220507]\n",
      "-------------------\n",
      "Pred: [0.10267045120710071, 0.9871190000598673, 0.11115306092377356]\n",
      "Error: [7.131309649505596e-06, 0.00016592015945769858, 0.0001243907679694045]\n",
      "Delta: [0.17, -0.82, 0.7100000000000001]\n",
      "Weights: [0.11407827911900079, 1.0967988889554081, 0.12350340102641506]\n",
      "Weight deltas: [0.002403406086390632, -0.011592899946119428, 0.010037754831396196]\n",
      "-------------------\n",
      "Pred: [0.10158891846822492, 0.992335805035621, 0.10663607124964528]\n",
      "Error: [2.5246618986662005e-06, 5.873988445201209e-05, 4.403744163036854e-05]\n",
      "Delta: [0.17, -0.82, 0.7100000000000001]\n",
      "Weights: [0.11287657607580547, 1.1025953389284677, 0.11848452361071697]\n",
      "Weight deltas: [0.0014300266214024207, -0.006897775467941081, 0.005972464124680743]\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Instead of predicting just whether the team won or lost,\n",
    "now we're also predicting whether they are happy/sad AND\n",
    "the percentage of the team that is hurt. We are making \n",
    "this prediction using only the current win/loss record\n",
    "\"\"\"\n",
    "\n",
    "weights = [0.3, 0.2, 0.9]\n",
    "\n",
    "def neural_network(inputs, weights):\n",
    "    pred = ele_mul(input, weights)\n",
    "    return pred\n",
    "\n",
    "wlrec = [0.9, 1.0, 1.0, 0.9]\n",
    "\n",
    "hurt = [0.1, 0.0, 0.0, 0.1]\n",
    "win = [1, 1, 0, 1]\n",
    "sad = [0.1, 0.0, 0.1, 0.2]\n",
    "\n",
    "input = wlrec[0]\n",
    "true = [hurt[0], win[0], sad[0]]\n",
    "\n",
    "for iter in range(10):\n",
    "\n",
    "    pred = neural_network(input, weights)\n",
    "\n",
    "    error = [0, 0, 0]\n",
    "    deltas = [0, 0, 0]\n",
    "\n",
    "    for i in range(len(true)):\n",
    "        error[i] = (pred[i] - true[i]) ** 2\n",
    "        deltas[i] = pred[i] - true[i]\n",
    "\n",
    "    weight_deltas = ele_mul(input, deltas)\n",
    "\n",
    "    alpha = 0.5\n",
    "\n",
    "    print(\"Pred: {}\".format(pred))\n",
    "    print(\"Error: {}\".format(error))\n",
    "    print(\"Delta: {}\".format(delta))\n",
    "    print(\"Weights: {}\".format(weights))\n",
    "    print(\"Weight deltas: {}\".format(weight_deltas))\n",
    "    print(\"-------------------\")\n",
    "\n",
    "    for i in range(len(weights)):\n",
    "        weights[i] -= (weight_deltas[i] * alpha)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent with Multiple Inputs & Outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8500000000000001, 0.065, -0.36]\n",
      "[[6.375000000000001, -7.947500000000001, -3.9099999999999997], [0.4875000000000001, -0.60775, -0.299], [0.9000000000000001, -1.122, -0.5519999999999999]]\n",
      "[[-0.027500000000000024, 0.25895, -0.2218], [0.09025, 0.212155, 0.00598], [-0.018000000000000002, 1.32244, 0.11104]]\n",
      "--------------------\n",
      "[-0.2337500000000002, 0.1683175, -0.26616]\n",
      "[[-2.836875000000002, -7.06930125, -3.1123600000000002], [-0.21693750000000014, -0.540593625, -0.23800400000000002], [-0.40050000000000024, -0.998019, -0.43939200000000006]]\n",
      "[[0.029237500000000013, 0.400336025, -0.1595528], [0.09458875, 0.22296687250000002, 0.01074008], [-0.009989999999999997, 1.34240038, 0.11982784]]\n",
      "--------------------\n",
      "[0.24851875000000012, 0.26021841625, -0.19146336]\n",
      "[[1.262409375000001, -6.288143461875, -2.47743856], [0.09653718750000008, -0.48085802943750006, -0.18945118400000002], [0.17822250000000014, -0.8877379005, -0.349756032]]\n",
      "[[0.003989312499999995, 0.5260988942375, -0.11000402879999999], [0.09265800625, 0.23258403308875003, 0.014529103680000002], [-0.01355445, 1.3601551380099999, 0.12682296064]]\n",
      "--------------------\n",
      "[0.033909156249999954, 0.341964281254375, -0.13200483455999998]\n",
      "[[-0.5617721718750004, -5.593303609337812, -1.97204109376], [-0.04295904843750003, -0.4277232171846562, -0.150803142464], [-0.07930901250000005, -0.7896428624947499, -0.27840580147199995]]\n",
      "[[0.015224755937500003, 0.6379649664242563, -0.07056320692479999], [0.09351718721874999, 0.24113849743244314, 0.017545166529280003], [-0.011968269749999998, 1.375947995259895, 0.13239107666944]]\n",
      "--------------------\n",
      "[0.12941042546875003, 0.4146772281757666, -0.08467584830975998]\n",
      "[[0.24998861648437526, -4.975243560505984, -1.5697447106329598], [0.01911677655468752, -0.3804598016857517, -0.12003930140134399], [0.03529251056250003, -0.7023873261890801, -0.22161101797171195]]\n",
      "[[0.010224983607812498, 0.7374698376343759, -0.039168312712140795], [0.09313485168765624, 0.2487476934661582, 0.019945952557306884], [-0.012674119961249999, 1.3899957417836766, 0.13682329702887425]]\n",
      "--------------------\n",
      "[0.08691236066640623, 0.4793553944623444, -0.04700197525456895]\n",
      "[[-0.1112449343355471, -4.425479147070074, -1.2495167896638362], [-0.008506965566835955, -0.3384189935994762, -0.09555128391546983], [-0.01570516720031253, -0.6247735266451868, -0.17640237030548275]]\n",
      "[[0.01244988229452344, 0.8259794205757773, -0.01417797691886407], [0.09330499099899296, 0.2555160733381477, 0.02185697823561628], [-0.012360016617243749, 1.4024912123165802, 0.1403513444349839]]\n",
      "--------------------\n",
      "[0.10582399950344923, 0.5368866233742553, -0.017013572302636882]\n",
      "[[0.0495039957793184, -3.93646370131883, -0.9946153645724135], [0.0037855996772419953, -0.3010236948067341, -0.07605882199671397], [0.006988799404139067, -0.5557360519508936, -0.14041628676316426]]\n",
      "[[0.01145980237893707, 0.904708694602154, 0.0057143303725842], [0.09322927900544813, 0.2615365472342824, 0.023378154675550558], [-0.01249979260532653, 1.4136059333555981, 0.1431596701702472]]\n",
      "--------------------\n",
      "[0.0974083202209651, 0.5880606514914001, 0.00685719644710104]\n",
      "[[-0.022029278121796697, -3.5014844623230994, -0.7917138301996413], [-0.0016845918563726887, -0.26776057653058993, -0.060542822309384334], [-0.0031100157348418864, -0.4943272182103199, -0.11177136426347876]]\n",
      "[[0.011900387941373004, 0.974738383848616, 0.021548606976577026], [0.09326297084257558, 0.2668917587648942, 0.024589011121738245], [-0.012437592290629691, 1.4234924777198046, 0.14539509745551676]]\n",
      "--------------------\n",
      "[0.10115329750167053, 0.6335799495016005, 0.02585832837189243]\n",
      "[[0.009803028764199438, -3.1145704292363963, -0.6302042088389144], [0.0007496433760858394, -0.2381730328239597, -0.048192086558269925], [0.0013839570020046266, -0.4397040605980794, -0.08897000595372909]]\n",
      "[[0.011704327366089015, 1.0370297924333438, 0.03415269115335531], [0.09324797797505387, 0.2716552194213734, 0.025552852852903644], [-0.012465271430669785, 1.4322865589317662, 0.14717449757459133]]\n",
      "--------------------\n",
      "[0.09948678261175663, 0.6740693650816735, 0.040983229384026376]\n",
      "[[-0.004362347800068715, -2.7704103968057754, -0.5016425502357759], [-0.0003335913023581959, -0.21185491269691226, -0.03836090090038286], [-0.0006158608658920539, -0.3911167619019918, -0.07082012473916835]]\n",
      "[[0.01179157432209039, 1.0924380003694594, 0.04418554215807083], [0.09325464980110103, 0.27589231767531164, 0.026320070870911302], [-0.012452954213351944, 1.440108894169806, 0.1485909000693747]]\n",
      "--------------------\n",
      "[0.10022838173776831, 0.7100847002401486, 0.05302265058968499]\n",
      "[[0.0019412447710305883, -2.464280047958737, -0.39930746998767763], [0.00014844812954939793, -0.18844494484390342, -0.03053527711670476], [0.0002740580853219654, -0.3478983597118217, -0.056372819292378015]]\n",
      "[[0.011752749426669777, 1.141723601328634, 0.05217169155782438], [0.09325168083851004, 0.27966121657218973, 0.026930776413245396], [-0.012458435375058384, 1.4470668613640423, 0.14971835645522225]]\n",
      "--------------------\n",
      "[0.09989837012669311, 0.7421203408636121, 0.06260602986938926]\n",
      "[[-0.0008638539231085735, -2.191977102659297, -0.3178487461101913], [-6.605941764947915e-05, -0.16762177843865214, -0.024306080584896982], [-0.00012195584796826919, -0.30945559096366543, -0.04487276415673289]]\n",
      "[[0.01177002650513195, 1.18556314338182, 0.05852866648002821], [0.09325300202686303, 0.28301365214096275, 0.027416898024943334], [-0.012455996258099018, 1.4532559731833157, 0.1506158117383569]]\n",
      "--------------------\n",
      "[0.10004522529362157, 0.770616043198183, 0.07023439977603385]\n",
      "[[0.00038441499578332344, -1.9497636328154444, -0.2530076019037123], [2.9396440854018853e-05, -0.14909957192118106, -0.019347640145578], [5.4270352345880954e-05, -0.2752607481621804, -0.035718720268759385]]\n",
      "[[0.011762338205216284, 1.2245584160381289, 0.06358881851810246], [0.09325241409804595, 0.2859956435793864, 0.027803850827854894], [-0.012457081665145937, 1.4587611881465592, 0.1513301861437321]]\n",
      "--------------------\n",
      "[0.0999798747443384, 0.7959629704247838, 0.07630658222172294]\n",
      "[[-0.00017106467312359014, -1.7343147513893375, -0.20139405111535502], [-1.3081416180039247e-05, -0.13262406922389053, -0.015400721555880091], [-2.4150306793918606e-05, -0.24484443549025942, -0.028432101333932473]]\n",
      "[[0.011765759498678755, 1.2592447110659157, 0.06761669954040955], [0.09325267572636955, 0.2886481249638642, 0.028111865258972496], [-0.012456598659010058, 1.4636580768563643, 0.15189882817041073]]\n",
      "--------------------\n",
      "[0.10000895573876942, 0.8185090621928452, 0.08114003944849146]\n",
      "[[7.612377953999938e-05, -1.5426729713608154, -0.1603096646878226], [5.8212302001176e-06, -0.1179691095746506, -0.012258974358480553], [1.074688652329403e-05, -0.2177891253685857, -0.02263195266181025]]\n",
      "[[0.011764237023087955, 1.290098170493132, 0.070822892834166], [0.09325255930176556, 0.2910075071553572, 0.028357044746142108], [-0.012456813596740524, 1.468013859363736, 0.15235146722364692]]\n",
      "--------------------\n",
      "[0.09999601469624762, 0.8385638108205359, 0.0849874714009992]\n",
      "[[-3.387508189525018e-05, -1.372207608025445, -0.12760649309150685], [-2.5904474390485435e-06, -0.10493352296665168, -0.009758143589350524], [-4.7823645028588486e-06, -0.19372342701535694, -0.018015034318800964]]\n",
      "[[0.011764914524725861, 1.317542322653641, 0.07337502269599613], [0.09325261111071434, 0.29310617761469027, 0.028552207617929117], [-0.012456717949450467, 1.4718883279040431, 0.15271176791002294]]\n",
      "--------------------\n",
      "[0.10000177346016982, 0.8564025097248666, 0.08805002723519535]\n",
      "[[1.5074411443431746e-05, -1.2205786673386334, -0.10157476850083955], [1.1527491103800747e-06, -0.09333836867883669, -0.007767482297123025], [2.128152203778599e-06, -0.17231698833016001, -0.014339967317765583]]\n",
      "[[0.011764613036496993, 1.3419538960004136, 0.07540651806601292], [0.09325258805573214, 0.294972944988267, 0.02870755726387158], [-0.012456760512494542, 1.4753346676706462, 0.15299856725637825]]\n",
      "--------------------\n",
      "[0.09999921081022445, 0.8722700324002689, 0.0904878216792155]\n",
      "[[-6.708113092238066e-06, -1.0857047245977143, -0.0808535157266683], [-5.129733541123227e-07, -0.08302447893982522, -0.006182915908509929], [-9.470277306689034e-07, -0.1532759611196773, -0.011414613984941407]]\n",
      "[[0.011764747198758838, 1.3636679904923679, 0.07702358838054629], [0.09325259831519922, 0.2966334345670635, 0.028831215582041776], [-0.01245674157193993, 1.4784001868930399, 0.1532268595360771]]\n",
      "--------------------\n",
      "[0.10000035118945012, 0.8863841938200392, 0.09242830605665554]\n",
      "[[2.9851103260022938e-06, -0.9657343525296669, -0.06435939851842792], [2.28273142576646e-07, -0.07385027401697453, -0.0049216010631739], [4.2142734014150026e-07, -0.13633896741595297, -0.009086032732013355]]\n",
      "[[0.011764687496552318, 1.3829826775429612, 0.07831077635091485], [0.09325259374973636, 0.29811044004740295, 0.028929647603305256], [-0.012456750000486733, 1.4811269662413589, 0.15340858019071735]]\n",
      "--------------------\n",
      "[0.0999998437206947, 0.8989387404029249, 0.09397293162109782]\n",
      "[[-1.3283740950692513e-06, -0.8590207065751385, -0.051230081220668564], [-1.0158154844647216e-07, -0.06568981873809883, -0.00391759444628642], [-1.8753516636271784e-07, -0.12127351151649014, -0.0072324820546826206]]\n",
      "[[0.01176471406403422, 1.400163091674464, 0.07933537797532822], [0.09325259578136734, 0.2994242364221649, 0.029007999492230985], [-0.012456746249783405, 1.4835524364716888, 0.153553229831811]]\n",
      "--------------------\n",
      "[0.10000006954429087, 0.9101060095884017, 0.09520245357039386]\n",
      "[[5.911264723754139e-07, -0.7640989184985855, -0.04077914465165221], [4.520378906400224e-08, -0.05843109376753889, -0.0031184051792439924], [8.345314904123491e-08, -0.10787278849391795, -0.0057570557155273705]]\n",
      "[[0.011764702241504773, 1.4154450700444359, 0.08015096086836127], [0.09325259487729155, 0.3005928582975157, 0.029070367595815865], [-0.012456747918846387, 1.4857098922415672, 0.15366837094612154]]\n",
      "--------------------\n",
      "[0.09999996905279057, 0.9200392955288833, 0.09618115304203352]\n",
      "[[-2.630512801887752e-07, -0.679665988004492, -0.03246019914271512], [-2.0115686132082813e-08, -0.05197445790622585, -0.002482250522678215], [-3.713665132076826e-08, -0.09595284536534003, -0.004582616349559782]]\n",
      "[[0.011764707502530376, 1.4290383898045258, 0.08080016485121556], [0.09325259527960528, 0.3016323474556402, 0.02912001260626943], [-0.01245674717611336, 1.4876289491488741, 0.15376002327311272]]\n",
      "--------------------\n",
      "[0.10000001377150819, 0.9288749533729418, 0.09696019782145868]\n",
      "[[1.1705781956250494e-07, -0.6045628963299947, -0.025838318517601294], [8.951480319485671e-09, -0.04623128030758784, -0.0019758714160518637], [1.6525809820588933e-08, -0.08535005595246985, -0.0036477626142495945]]\n",
      "[[0.011764705161373984, 1.4411296477311257, 0.08131693122156759], [0.09325259510057567, 0.30255697306179197, 0.02915953003459047], [-0.012456747506629557, 1.4893359502679235, 0.1538329785253977]]\n",
      "--------------------\n",
      "[0.09999999387167886, 0.9367342710252318, 0.09758031746588111]\n",
      "[[-5.2090729708853534e-08, -0.53775869628553, -0.020567301540010602], [-3.983408742441741e-09, -0.04112272383359935, -0.0015727936471772814], [-7.353985370661675e-09, -0.07591887476972188, -0.002903619040942673]]\n",
      "[[0.011764706203188579, 1.4518848216568363, 0.08172827725236781], [0.09325259518024384, 0.303379427538464, 0.029190985907534016], [-0.012456747359549849, 1.490854327763318, 0.15389105090621655]]\n",
      "--------------------\n",
      "[0.10000000272710292, 0.9437251340769436, 0.09807393270284137]\n",
      "[[2.3180374807141302e-08, -0.47833636034597954, -0.016371572025848394], [1.7726168970166878e-09, -0.03657866284998667, -0.0012519437431531126], [3.2725235021846544e-09, -0.0675298391076677, -0.0023112807565903613]]\n",
      "[[0.011764705739581082, 1.4614515488637558, 0.08205570869288478], [0.0932525951447915, 0.3041110007954637, 0.029216024782397078], [-0.012456747425000319, 1.4922049245454714, 0.15393727652134837]]\n",
      "--------------------\n",
      "[0.0999999987864392, 0.9499435067614413, 0.09846685043146174]\n",
      "[[-1.0315266862903627e-08, -0.42548019252774855, -0.013031771332575291], [-7.888145248102774e-10, -0.03253672060506312, -0.0009965472195498752], [-1.456272968880512e-09, -0.06006779188627038, -0.0018397794822459235]]\n",
      "[[0.01176470594588642, 1.4699611527143108, 0.08231634411953628], [0.0932525951605678, 0.304761735207565, 0.029235955726788075], [-0.01245674739587486, 1.493406280383197, 0.1539740721109933]]\n",
      "--------------------\n",
      "[0.10000000054003456, 0.9554747492643021, 0.09877961294344353]\n",
      "[[4.590293749273666e-09, -0.3784646312534322, -0.010373289980730005], [3.51022463179751e-10, -0.02894141297820364, -0.0007932515867617063], [6.48041470485694e-10, -0.05343030088283749, -0.0014644644678677653]]\n",
      "[[0.011764705854080544, 1.4775304453393794, 0.08252380991915088], [0.09325259515354735, 0.30534056346712907, 0.029251820758523308], [-0.012456747408835688, 1.4944748864008537, 0.15400336140035065]]\n",
      "--------------------\n",
      "[0.09999999975968463, 0.9603947894705966, 0.09902857190298106]\n",
      "[[-2.0426807190165874e-09, -0.33664428949992853, -0.008257138824661031], [-1.56204996160092e-10, -0.025743386844112183, -0.0006314282630623142], [-2.8837845444940055e-10, -0.047526252635284025, -0.0011657137164227337]]\n",
      "[[0.011764705894934158, 1.484263331129378, 0.08268895269564411], [0.09325259515667145, 0.3058554312040113, 0.029264449323784553], [-0.01245674740306812, 1.4954254114535594, 0.1540266756746791]]\n",
      "--------------------\n",
      "[0.10000000010694035, 0.9647711652340958, 0.09922674323477293]\n",
      "[[9.089929364769489e-10, -0.29944509551018583, -0.006572682504430147], [6.951122455411963e-11, -0.02289874259783774, -0.0005026168973975995], [1.283284145614516e-10, -0.04227460171908506, -0.0009279081182724913]]\n",
      "[[0.0117647058767543, 1.4902522330395818, 0.0828204063457327], [0.09325259515528123, 0.3063134060559681, 0.029274501661732504], [-0.012456747405634688, 1.4962709034879411, 0.15404523383704455]]\n",
      "--------------------\n",
      "[0.09999999995241154, 0.9686639514757281, 0.09938448761487924]\n",
      "[[-4.0450191807206437e-10, -0.26635641245631075, -0.005231855273526521], [-3.093249961727551e-11, -0.020368431540776704, -0.0004000830503284987], [-5.710615313958556e-11, -0.037603258229126225, -0.0007386148621449206]]\n",
      "[[0.011764705884844339, 1.495579361288708, 0.08292504345120323], [0.09325259515589987, 0.3067207746867836, 0.029282503322739073], [-0.012456747404492565, 1.4970229686525236, 0.15406000613428744]]\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# 1. An empty Network With Multiple Inputs & Outputs\n",
    "            #toes %win #fans\n",
    "weights = [ [0.1, 0.1, -0.3], #hurt?\n",
    "            [0.1, 0.2, 0.0], # win?\n",
    "            [0.0, 1.3, 0.1]] #sad?\n",
    "\n",
    "def neural_network(input, weights):\n",
    "    pred = vect_mat_mul(inputs, weights)\n",
    "    return pred\n",
    "\n",
    "def vect_mat_mul(vector, matrix):\n",
    "    assert(len(vector) == len(matrix[0]))\n",
    "    \n",
    "    result = []\n",
    "    for row in matrix:\n",
    "        result.append([x*y for x,y in zip(vector,row)])\n",
    "    return result\n",
    "\n",
    "# 2. PREDICT: Make a Prediction and Calculate Error and Delta\n",
    "\n",
    "toes = [8.5, 9.5, 9.9, 9.0]\n",
    "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "\n",
    "hurt = [0.1, 0.0, 0.0, 0.1]\n",
    "win = [1, 1, 0, 1]\n",
    "sad = [0.1, 0.0, 0.1, 0.2]\n",
    "\n",
    "alpha = 0.020\n",
    "\n",
    "input = [toes[0], wlrec[0], nfans[0]]\n",
    "true = [hurt[0], win[0], sad[0]]\n",
    "\n",
    "for i in range(30):\n",
    "\n",
    "    pred = neural_network(input, weights)\n",
    "    pred = pred[0]\n",
    "    \n",
    "    print(pred)\n",
    "\n",
    "    error = [0, 0, 0]\n",
    "    deltas = [0,0,0]\n",
    "\n",
    "    def zeros_matrix(m,n):\n",
    "        return [[0 for i in range(n)] for i in range(m)]\n",
    "\n",
    "    for i in range(len(true)):\n",
    "        error[i] = (pred[i] - true[i]) ** 2\n",
    "        deltas[i] = pred[i] - true[i]\n",
    "\n",
    "# 3. COMPARE: Calculating Each weight_delta and putting it on each weight\n",
    "\n",
    "    def outer_prod(vec_a, vec_b):\n",
    "        out = zeros_matrix(len(vec_a), len(vec_b))\n",
    "        for i in range(len(vec_a)):\n",
    "            for j in range(len(vec_b)):\n",
    "                out[i][j] = vec_a[i] * vec_b[j]\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "    weight_deltas = outer_prod(input, deltas)\n",
    "\n",
    "# 4. LEARN: Updating the weights\n",
    "\n",
    "    print(weight_deltas)\n",
    "\n",
    "    for i in range(len(weights)):\n",
    "        for j in range(len(weights[0])):\n",
    "            weights[i][j] -= alpha * weight_deltas[i][j]\n",
    "\n",
    "    print(weights)\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Backpropagation\n",
    "\n",
    "### A street light problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [ 0.04] Prediction: -0.19999999999999996\n",
      "Error: [ 0.0256] Prediction: -0.15999999999999992\n",
      "Error: [ 0.016384] Prediction: -0.1279999999999999\n",
      "Error: [ 0.01048576] Prediction: -0.10239999999999982\n",
      "Error: [ 0.00671089] Prediction: -0.08191999999999977\n",
      "Error: [ 0.00429497] Prediction: -0.06553599999999982\n",
      "Error: [ 0.00274878] Prediction: -0.05242879999999994\n",
      "Error: [ 0.00175922] Prediction: -0.04194304000000004\n",
      "Error: [ 0.0011259] Prediction: -0.03355443200000008\n",
      "Error: [ 0.00072058] Prediction: -0.02684354560000002\n",
      "Error: [ 0.00046117] Prediction: -0.021474836479999926\n",
      "Error: [ 0.00029515] Prediction: -0.01717986918399994\n",
      "Error: [ 0.00018889] Prediction: -0.013743895347199997\n",
      "Error: [ 0.00012089] Prediction: -0.010995116277759953\n",
      "Error: [  7.73712525e-05] Prediction: -0.008796093022207963\n",
      "Error: [  4.95176016e-05] Prediction: -0.007036874417766459\n",
      "Error: [  3.16912650e-05] Prediction: -0.0056294995342132115\n",
      "Error: [  2.02824096e-05] Prediction: -0.004503599627370569\n",
      "Error: [  1.29807421e-05] Prediction: -0.003602879701896544\n",
      "Error: [  8.30767497e-06] Prediction: -0.002882303761517324\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "weights = np.array([0.5, 0.48, -0.7])\n",
    "\n",
    "alpha = 0.1\n",
    "\n",
    "streetlights = np.array([[1, 0, 1],\n",
    "                        [0, 1, 1], \n",
    "                        [0, 0, 1],\n",
    "                        [1, 1, 1],\n",
    "                        [0, 1, 1],\n",
    "                        [1, 0, 1]])\n",
    "\n",
    "walk_vs_stop = np.array([[0], [1], [0], [1], [1], [0]])\n",
    "\n",
    "input = streetlights[0] # [1, 0, 1]\n",
    "goal_prediction = walk_vs_stop[0] # equals 0 i.e. stop\n",
    "\n",
    "# training on one example \n",
    "for iteration in range(20):\n",
    "    prediction = input.dot(weights)\n",
    "    error = (prediction - goal_prediction) ** 2\n",
    "    delta = prediction - goal_prediction\n",
    "    weights = weights - alpha * (input * delta)\n",
    "    \n",
    "    print(\"Error: {} Prediction: {}\".format(error, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: -0.0023058430092137705\n",
      "Prediction: -0.1209223372036855\n",
      "Prediction: -0.4888301034833169\n",
      "Prediction: 0.7512228033816979\n",
      "Prediction: 0.20190057990904375\n",
      "Prediction: 0.2886959509940853\n",
      "Weights: [ 0.59508579  0.6967799  -0.36412903]\n",
      "Error: [ 2.2776252] \n",
      "\n",
      "Prediction: 0.23095676079526822\n",
      "Prediction: 0.3095551927482997\n",
      "Prediction: -0.31818022191782463\n",
      "Prediction: 1.0514522876696315\n",
      "Prediction: 0.46917171885649595\n",
      "Prediction: 0.3284202821335913\n",
      "Weights: [ 0.53400285  0.81376198 -0.27126663]\n",
      "Error: [ 1.02357959] \n",
      "\n",
      "Prediction: 0.26273622570687305\n",
      "Prediction: 0.5162217243011503\n",
      "Prediction: -0.24916242359281637\n",
      "Prediction: 1.1456228535284017\n",
      "Prediction: 0.6087690510945215\n",
      "Prediction: 0.2934815746795325\n",
      "Weights: [ 0.46381879  0.88670061 -0.22903353]\n",
      "Error: [ 0.62555276] \n",
      "\n",
      "Prediction: 0.23478525974362602\n",
      "Prediction: 0.6341885574333014\n",
      "Prediction: -0.21593091088147304\n",
      "Prediction: 1.1692841999678323\n",
      "Prediction: 0.6950870970412221\n",
      "Prediction: 0.24263689344202927\n",
      "Weights: [ 0.39914815  0.93684463 -0.20503864]\n",
      "Error: [ 0.41606997] \n",
      "\n",
      "Prediction: 0.19410951475362342\n",
      "Prediction: 0.7123950368134124\n",
      "Prediction: -0.19568909399513768\n",
      "Prediction: 1.1692221409669388\n",
      "Prediction: 0.7556405106568559\n",
      "Prediction: 0.19420853826199794\n",
      "Weights: [ 0.34339413  0.97311886 -0.1880273 ]\n",
      "Error: [ 0.28475399] \n",
      "\n",
      "Prediction: 0.15536683060959836\n",
      "Prediction: 0.7695548716383251\n",
      "Prediction: -0.1805194738089955\n",
      "Prediction: 1.1615532958244013\n",
      "Prediction: 0.8013851855266794\n",
      "Prediction: 0.1529407469871975\n",
      "Weights: [ 0.29640805  0.99986952 -0.17405545]\n",
      "Error: [ 0.19876927] \n",
      "\n",
      "Prediction: 0.12235259758975803\n",
      "Prediction: 0.813578813963648\n",
      "Prediction: -0.16764859041726432\n",
      "Prediction: 1.151800697305351\n",
      "Prediction: 0.8372677707515747\n",
      "Prediction: 0.11920213918094039\n",
      "Weights: [ 0.2570725   1.01960479 -0.16171079]\n",
      "Error: [ 0.14156345] \n",
      "\n",
      "Prediction: 0.0953617113447523\n",
      "Prediction: 0.8483578315486905\n",
      "Prediction: -0.15608274638866876\n",
      "Prediction: 1.1418308721874209\n",
      "Prediction: 0.8659283654403351\n",
      "Prediction: 0.09210284957828199\n",
      "Weights: [ 0.22414296  1.03399309 -0.15046068]\n",
      "Error: [ 0.10302516] \n",
      "\n",
      "Prediction: 0.07368227966262561\n",
      "Prediction: 0.8761641794281774\n",
      "Prediction: -0.14544532637948598\n",
      "Prediction: 1.1322506083472592\n",
      "Prediction: 0.8890257545110386\n",
      "Prediction: 0.07052124130467569\n",
      "Weights: [ 0.19649755  1.04424903 -0.14008055]\n",
      "Error: [ 0.07669748] \n",
      "\n",
      "Prediction: 0.05641699304374054\n",
      "Prediction: 0.8985267801739892\n",
      "Prediction: -0.1355749314796077\n",
      "Prediction: 1.1232347651843533\n",
      "Prediction: 0.9077319642502817\n",
      "Prediction: 0.05341826010365544\n",
      "Weights: [ 0.17319055  1.05129968 -0.13045594]\n",
      "Error: [ 0.05841396] \n",
      "\n",
      "Prediction: 0.04273460808292437\n",
      "Prediction: 0.9165702845815674\n",
      "Prediction: -0.12638642655192514\n",
      "Prediction: 1.1148119548805544\n",
      "Prediction: 0.9229324793443356\n",
      "Prediction: 0.039913661752830856\n",
      "Weights: [ 0.15344452  1.05586821 -0.12151359]\n",
      "Error: [ 0.04547458] \n",
      "\n",
      "Prediction: 0.03193092940226468\n",
      "Prediction: 0.931161524359959\n",
      "Prediction: -0.11782283887072709\n",
      "Prediction: 1.106962933331583\n",
      "Prediction: 0.9353189167087234\n",
      "Prediction: 0.029286396635699624\n",
      "Weights: [ 0.1366265   1.05852387 -0.11319738]\n",
      "Error: [ 0.03612295] \n",
      "\n",
      "Prediction: 0.023429117308559705\n",
      "Prediction: 0.9429835819725526\n",
      "Prediction: -0.10983864957936619\n",
      "Prediction: 1.0996543157649374\n",
      "Prediction: 0.9454398673829914\n",
      "Prediction: 0.02095395071624251\n",
      "Weights: [ 0.12222276  1.0597161  -0.1054596 ]\n",
      "Error: [ 0.02921118] \n",
      "\n",
      "Prediction: 0.016763160572994013\n",
      "Prediction: 0.9525801827774695\n",
      "Prediction: -0.10239393234289304\n",
      "Prediction: 1.0928499819798063\n",
      "Prediction: 0.9537335430603038\n",
      "Prediction: 0.014448552712945928\n",
      "Weights: [ 0.10981659  1.05979973 -0.09825775]\n",
      "Error: [ 0.02398462] \n",
      "\n",
      "Prediction: 0.011558842170356742\n",
      "Prediction: 0.9603860949599128\n",
      "Prediction: -0.0954522405969363\n",
      "Prediction: 1.0865148048648543\n",
      "Prediction: 0.9605511390546531\n",
      "Prediction: 0.009395613421551582\n",
      "Weights: [ 0.09906966  1.05905452 -0.09155317]\n",
      "Error: [ 0.0199433] \n",
      "\n",
      "Prediction: 0.007516490737241269\n",
      "Prediction: 0.9667497008278431\n",
      "Prediction: -0.08897979142785699\n",
      "Prediction: 1.0806157537399257\n",
      "Prediction: 0.966174589057075\n",
      "Prediction: 0.005495591996101765\n",
      "Weights: [ 0.08970688  1.05770052 -0.08531041]\n",
      "Error: [ 0.01675274] \n",
      "\n",
      "Prediction: 0.004396473596881403\n",
      "Prediction: 0.9719504646863616\n",
      "Prediction: -0.08294509959270584\n",
      "Prediction: 1.0751221137099347\n",
      "Prediction: 0.9708304589663729\n",
      "Prediction: 0.002509173729515299\n",
      "Weights: [ 0.0815041   1.05591021 -0.07949676]\n",
      "Error: [ 0.01418649] \n",
      "\n",
      "Prediction: 0.0020073389836122307\n",
      "Prediction: 0.9762127159017855\n",
      "Prediction: -0.07731876976255733\n",
      "Prediction: 1.0700054190569526\n",
      "Prediction: 0.9747009658862935\n",
      "Prediction: 0.00024529617294709316\n",
      "Weights: [ 0.0742783   1.0538183  -0.07408206]\n",
      "Error: [ 0.01208892] \n",
      "\n",
      "Prediction: 0.00019623693835767175\n",
      "Prediction: 0.9797166193979042\n",
      "Prediction: -0.07207334653154711\n",
      "Prediction: 1.065239304313921\n",
      "Prediction: 0.977932769308694\n",
      "Prediction: -0.0014484755296031715\n",
      "Weights: [ 0.06787959  1.05152943 -0.06903837]\n",
      "Error: [ 0.01035125] \n",
      "\n",
      "Prediction: -0.0011587804236825316\n",
      "Prediction: 0.9826069410422836\n",
      "Prediction: -0.0671831877495537\n",
      "Prediction: 1.0607993409151615\n",
      "Prediction: 0.98064400342575\n",
      "Prediction: -0.0026936681938263263\n",
      "Weights: [ 0.0621849   1.04912441 -0.06433984]\n",
      "Error: [ 0.00889591] \n",
      "\n",
      "Prediction: -0.002154934555061057\n",
      "Prediction: 0.9850000630154887\n",
      "Prediction: -0.0626243494353496\n",
      "Prediction: 1.056662880845678\n",
      "Prediction: 0.9829299091867906\n",
      "Prediction: -0.0035870860898773935\n",
      "Weights: [ 0.05709282  1.04666512 -0.05996248]\n",
      "Error: [ 0.00766639] \n",
      "\n",
      "Prediction: -0.0028696688719019106\n",
      "Prediction: 0.9869896028456103\n",
      "Prediction: -0.05837447828344459\n",
      "Prediction: 1.0528089130061948\n",
      "Prediction: 0.9848673475035937\n",
      "Prediction: -0.004205764905336445\n",
      "Weights: [ 0.05251947  1.04419853 -0.05588408]\n",
      "Error: [ 0.00662055] \n",
      "\n",
      "Prediction: -0.003364611924269151\n",
      "Prediction: 0.9886509156858355\n",
      "Prediction: -0.05441271039170197\n",
      "Prediction: 1.0492179328715419\n",
      "Prediction: 0.9865184170135304\n",
      "Prediction: -0.004610938344490077\n",
      "Weights: [ 0.04839523  1.04175981 -0.05208398]\n",
      "Error: [ 0.00572628] \n",
      "\n",
      "Prediction: -0.003688750675592066\n",
      "Prediction: 0.9900447025128325\n",
      "Prediction: -0.05071957569031403\n",
      "Prediction: 1.0458718244778547\n",
      "Prediction: 0.9879333546837266\n",
      "Prediction: -0.004851213586669081\n",
      "Weights: [ 0.04466204  1.03937482 -0.04854301]\n",
      "Error: [ 0.00495855] \n",
      "\n",
      "Prediction: -0.003880970869335268\n",
      "Prediction: 0.9912199021925816\n",
      "Prediction: -0.04727690781109847\n",
      "Prediction: 1.0427537534315474\n",
      "Prediction: 0.9891528618488656\n",
      "Prediction: -0.004965113004812567\n",
      "Weights: [ 0.04127128  1.03706217 -0.04524337]\n",
      "Error: [ 0.00429745] \n",
      "\n",
      "Prediction: -0.003972090403850055\n",
      "Prediction: 0.9922160098199589\n",
      "Prediction: -0.04406775919915956\n",
      "Prediction: 1.0398480696699668\n",
      "Prediction: 0.9902099698418897\n",
      "Prediction: -0.00498310830334231\n",
      "Weights: [ 0.03818199  1.03483476 -0.04216848]\n",
      "Error: [ 0.00372688] \n",
      "\n",
      "Prediction: -0.003986486642673842\n",
      "Prediction: 0.9930649353681134\n",
      "Prediction: -0.041076321272638966\n",
      "Prediction: 1.037140218843443\n",
      "Prediction: 0.991131536653066\n",
      "Prediction: -0.004929248157681733\n",
      "Weights: [ 0.03535954  1.03270109 -0.03930294]\n",
      "Error: [ 0.00323359] \n",
      "\n",
      "Prediction: -0.003943398526145385\n",
      "Prediction: 0.9937924939908355\n",
      "Prediction: -0.03828784942572682\n",
      "Prediction: 1.034616661340968\n",
      "Prediction: 0.9919394478670475\n",
      "Prediction: -0.004822460332325515\n",
      "Weights: [ 0.03277446  1.03066623 -0.03663243]\n",
      "Error: [ 0.00280658] \n",
      "\n",
      "Prediction: -0.0038579682658604064\n",
      "Prediction: 0.9944196011534567\n",
      "Prediction: -0.03568859265948276\n",
      "Prediction: 1.0322647981201623\n",
      "Prediction: 0.9926515805646812\n",
      "Prediction: -0.00467759314258628\n",
      "Weights: [ 0.03040154  1.02873264 -0.03414361]\n",
      "Error: [ 0.0024366] \n",
      "\n",
      "Prediction: -0.0037420745140690215\n",
      "Prediction: 0.9949632312174104\n",
      "Prediction: -0.03326572761809433\n",
      "Prediction: 1.0300729026208357\n",
      "Prediction: 0.9932825772115706\n",
      "Prediction: -0.004506248216511032\n",
      "Weights: [ 0.02821908  1.02690076 -0.03182408]\n",
      "Error: [ 0.00211579] \n",
      "\n",
      "Prediction: -0.0036049985732088258\n",
      "Prediction: 0.9954371864482284\n",
      "Prediction: -0.031007296805376384\n",
      "Prediction: 1.0280300581411068\n",
      "Prediction: 0.9938444672108991\n",
      "Prediction: -0.004317446172163543\n",
      "Weights: [ 0.02620832  1.02516959 -0.02966228]\n",
      "Error: [ 0.00183748] \n",
      "\n",
      "Prediction: -0.0034539569377308316\n",
      "Prediction: 0.9958527140797087\n",
      "Prediction: -0.028902150757020767\n",
      "Prediction: 1.0261261001383342\n",
      "Prediction: 0.994347166311802\n",
      "Prediction: -0.004118158541300487\n",
      "Weights: [ 0.02435292  1.023537   -0.02764745]\n",
      "Error: [ 0.00159595] \n",
      "\n",
      "Prediction: -0.0032945268330403926\n",
      "Prediction: 0.9962190015868758\n",
      "Prediction: -0.026939893947585798\n",
      "Prediction: 1.024351562986725\n",
      "Prediction: 0.9947988780669142\n",
      "Prediction: -0.003913732634397749\n",
      "Weights: [ 0.02263859  1.02200005 -0.02576958]\n",
      "Error: [ 0.00138628] \n",
      "\n",
      "Prediction: -0.0031309861075182015\n",
      "Prediction: 0.9965435743277229\n",
      "Prediction: -0.025110834216771842\n",
      "Prediction: 1.0226976307818405\n",
      "Prediction: 0.9952064167274873\n",
      "Prediction: -0.0037082307262265024\n",
      "Weights: [ 0.02105275  1.02055529 -0.02401933]\n",
      "Error: [ 0.00120422] \n",
      "\n",
      "Prediction: -0.002966584580981202\n",
      "Prediction: 0.9968326149127107\n",
      "Prediction: -0.02340593550657774\n",
      "Prediction: 1.0211560918313483\n",
      "Prediction: 0.9955754671145567\n",
      "Prediction: -0.0035047006831235746\n",
      "Weights: [ 0.01958427  1.01919887 -0.02238803]\n",
      "Error: [ 0.00104611] \n",
      "\n",
      "Prediction: -0.002803760546498859\n",
      "Prediction: 0.9970912198146076\n",
      "Prediction: -0.021816773709008974\n",
      "Prediction: 1.0197192965129362\n",
      "Prediction: 0.9959107939199998\n",
      "Prediction: -0.003305391742346179\n",
      "Weights: [ 0.01822325  1.01792674 -0.02086757]\n",
      "Error: [ 0.00090879] \n",
      "\n",
      "Prediction: -0.0026443133938769438\n",
      "Prediction: 0.9973236056496222\n",
      "Prediction: -0.02033549543274159\n",
      "Prediction: 1.0183801182156498\n",
      "Prediction: 0.9962164104198419\n",
      "Prediction: -0.003111926421903756\n",
      "Weights: [ 0.01696086  1.01673473 -0.01945041]\n",
      "Error: [ 0.00078952] \n",
      "\n",
      "Prediction: -0.0024895411375230048\n",
      "Prediction: 0.9975332750918161\n",
      "Prediction: -0.01895477950625553\n",
      "Prediction: 1.017131917111134\n",
      "Prediction: 0.9964957146018517\n",
      "Prediction: -0.0029254373509864165\n",
      "Weights: [ 0.01578917  1.01561864 -0.01812952]\n",
      "Error: [ 0.00068591] \n",
      "\n",
      "Prediction: -0.0023403498807891346\n",
      "Prediction: 0.9977231504046589\n",
      "Prediction: -0.01766780104421687\n",
      "Prediction: 1.0159685065272686\n",
      "Prediction: 0.9967515991226952\n",
      "Prediction: -0.0027466760583987337\n",
      "Weights: [ 0.01470102  1.01457431 -0.01689836]\n",
      "Error: [ 0.0005959] \n",
      "\n",
      "Prediction: -0.0021973408467189856\n",
      "Prediction: 0.9978956809886679\n",
      "Prediction: -0.016468197913146573\n",
      "Prediction: 1.0148841217191535\n",
      "Prediction: 0.9969865402384182\n",
      "Prediction: -0.0025760993525998453\n",
      "Weights: [ 0.01368995  1.01359768 -0.01575083]\n",
      "Error: [ 0.00051771] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Expanding for all street lights\n",
    "for iteration in range(40):\n",
    "    error_for_all_lights = 0\n",
    "    # This thing learns one at a time - Stochastic Gradient Descent\n",
    "    for row_index in range(len(walk_vs_stop)):\n",
    "        input = streetlights[row_index]\n",
    "        goal_prediction = walk_vs_stop[row_index]\n",
    "        \n",
    "        prediction = input.dot(weights)\n",
    "        \n",
    "        error = (prediction - goal_prediction) ** 2\n",
    "        error_for_all_lights += error\n",
    "        \n",
    "        delta = prediction - goal_prediction\n",
    "        weights = weights - (alpha * (input * delta))\n",
    "        print(\"Prediction: {}\".format(prediction))\n",
    "    print(\"Weights: {}\".format(weights))\n",
    "    print(\"Error: {} \\n\".format(error_for_all_lights))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network **identified correlation** between the middle input and output! Inversely, *randomness* with respect to the output was found at the far left and far right weights (values near 0).\n",
    "\n",
    "Above is *Stochastic Gradient Descent*. *Full/Average Gradient Descent* configuration would calculate the average weight_delta over the entire dataset, only actually changing the weights each time it computes a full average, instead of computing weight_delta for each of the rows above.\n",
    "\n",
    "There is a 3rd configuration *Batch Gradient Descent*, more about it later.\n",
    "\n",
    "The greatest challenge you will face with deep learning is convincing your neural network to *generalize* instead of just *memorize*. Beware of overfitting when the neural network stops learning!\n",
    "\n",
    "Neural networks search for corellation between their input and output *layers*. We set the values of our input layer to be individual rows of our input data and we try to train the network so that our output layer equals our output dataset. The neural network doesnt actually *know* about data. It just searches for corellation between the input and output layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation: Long Distance Error Atribution\n",
    "### If your data doesn't have correlation... let's create intermediate data that does!\n",
    "\n",
    "Stack the network.\n",
    "\n",
    "Here is a problem - For any two consecutive weighted sums of the input, there exists a single weighted sum with exactly identical behavior. Aka... anything that our 3 layer network can do... our 2 layer network can also do.\n",
    "\n",
    "## Enter Non-linearity\n",
    "\n",
    "By turning any middle node off whenever it would be negative, we allow the network to sometimes subscribe to correlation from various inputs. This is impossible for 2-layer neural networks... thus adding power to 3-layer nets.\n",
    "\n",
    "\"If the node would be negative then set it to 0\" logic is called a **nonlinearity**. This is because without this tweak, our neural network is **linear**. Without this technique, our output layer only gets to pick from the same correlation that it had in the 2-layer network. It's still just subscribing to pieces of the input layer, which means that it can't solve our new streetlights dataset.\n",
    "\n",
    "There are many kinds of nonlinearities. However, the one we discussed above is, in\n",
    "many cases, the best one to use. It's also the simplest. (It's called \"relu\")\n",
    "\n",
    "## * Sidenote *\n",
    "\n",
    "*We can compute the relationship between our error and any one of our weights so that we know how changing the weight changes the error. We can then use this to reduce our error down to 0.*\n",
    "\n",
    "*Adjusting our weights to reduce our error over a series of training examples ultimately just searches for correlation between our input and our output layers. If no correlation exists, then error will never reach 0.*\n",
    "\n",
    "## Our first \"Deep\" Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.37242104  0.51828245 -1.16138222 -0.02489585]\n",
      "[-0.          0.51828245 -0.         -0.        ]\n",
      "[ 0.39194327]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "def relu(x):\n",
    "    return (x > 0) * x\n",
    "\n",
    "alpha = 0.2\n",
    "hidden_size = 4\n",
    "\n",
    "streetlights = np.array([[1, 0, 1],\n",
    "                         [0, 1, 1],\n",
    "                         [0, 0, 1],\n",
    "                         [1, 1, 1]])\n",
    "\n",
    "walk_vs_stop = np.array([[1, 1, 0, 0]]).T\n",
    "\n",
    "# 2 sets of weights now to connect our 3 layers (randomly initialized)\n",
    "# 3 by hidden_size array of random numbers from [-1, 1)\n",
    "weights_0_1 = 2 * np.random.random((3, hidden_size)) - 1\n",
    "# hidden_size by 1 array of random numbers from [-1, 1)\n",
    "weights_1_2 = 2 * np.random.random((hidden_size, 1)) - 1\n",
    "\n",
    "layer_0 = streetlights[0]\n",
    "# The output of layer_1 is sent through \"relu\" where \n",
    "# negative values become 0\n",
    "# This is then the input for the next layer, layer_2\n",
    "layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "# This works because of numpy array. It applys relu to each element\n",
    "# So layer_1 provides an output (input to layer_2) only if the error is positive\n",
    "layer_2 = np.dot(layer_1, weights_1_2)\n",
    "print(np.dot(layer_0, weights_0_1))\n",
    "print(layer_1)\n",
    "print(layer_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation in Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.6342311598444467\n",
      "Error: 0.35838407676317513\n",
      "Error: 0.0830183113303298\n",
      "Error: 0.006467054957103705\n",
      "Error: 0.0003292669000750734\n",
      "Error: 1.5055622665134859e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# returns x if x > 0\n",
    "# returns 0 otherwise\n",
    "def relu(x):\n",
    "    return (x > 0) * x\n",
    "\n",
    "# returns 1 for input > 0\n",
    "# return 0 otherwise\n",
    "def relu2deriv(output):\n",
    "    return output > 0\n",
    "\n",
    "alpha = 0.2\n",
    "hidden_size = 4\n",
    "\n",
    "streetlights = np.array([[1, 0, 1],\n",
    "                         [0, 1, 1],\n",
    "                         [0, 0, 1],\n",
    "                         [1, 1, 1]])\n",
    "\n",
    "walk_vs_stop = np.array([[1, 1, 0, 0]]).T\n",
    "\n",
    "weights_0_1 = 2 * np.random.random((3, hidden_size)) - 1\n",
    "weights_1_2 = 2 * np.random.random((hidden_size, 1)) - 1\n",
    "\n",
    "for iteration in range(60):\n",
    "    layer_2_error = 0\n",
    "    \n",
    "    for i in range(len(streetlights)):\n",
    "        layer_0 = streetlights[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "        layer_2 = np.dot(layer_1, weights_1_2)\n",
    "        \n",
    "        # using i:i+1 so that it returns [[0]] not just [0], which would \n",
    "        # cause shapes to mismatch (0 dimensions)\n",
    "        layer_2_error += np.sum((layer_2 - walk_vs_stop[i:i+1]) ** 2)\n",
    "        \n",
    "        # How much higher or lower we want the output prediction to be??\n",
    "        layer_2_delta = (walk_vs_stop[i:i+1] - layer_2)\n",
    "        \n",
    "        # How much we want each middle node to move up or down??\n",
    "        \n",
    "        # This line computes the delta at layer_1 given the delta at layer_2 by\n",
    "        # taking the layer_2_delta and multiplying it by its connecting weights_1_2\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T)*relu2deriv(layer_1)\n",
    "        \n",
    "        # Note the goal_pred - pred instead of pred - goal_pred for layer_2_delta, hence the += not -=\n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "        \n",
    "    if(iteration % 10 == 9):\n",
    "        print(\"Error: {}\".format(layer_2_error))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *relu2deriv* function returns 1 when output is > 0 and it returns 0 otherwise. This is actually the *slope* of our relu function. It's the *derivative* of our relu function. It serves a very important purpose.\n",
    "\n",
    "The goal here is **error attribution**. It is all about figuring out how much each weight contributed to the final error. layer_2_delta tells us how much we want the final prediction to move up or down.  layer_1_delta will tell us how much we want each middle node to move up or down. Multiplying the output delta by each weight attached to it will give us a weighting of how much each weight contributed to that error!!\n",
    "\n",
    "Theres one more thing though - If the relu set the output to a  layer_1 node to be 0, then it didn't contribute to the error at all. So, when this was true, we should also set the delta of that node to be zero. Multiplying each layer_1 node by the relu2deriv function accomplishes this! relu2deriv is either a 1 or a  depending on whether the layer_1 value was > 0 or not.\n",
    "\n",
    "## One Iteration of Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. Initialize the Network's Weights and Data\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "def relu(x):\n",
    "    return (x > 0) * x\n",
    "\n",
    "def relu2deriv(output):\n",
    "    return output > 0\n",
    "\n",
    "lights = np.array( [[1, 0, 1],\n",
    "                    [0, 1, 1],\n",
    "                    [0, 0, 1],\n",
    "                    [1, 1, 1]])\n",
    "\n",
    "walk_stop = np.array([[1, 1, 0, 0]]).T\n",
    "\n",
    "alpha = 0.2\n",
    "hidden_size = 4\n",
    "\n",
    "weights_0_1 = 2 * np.random.random((3, hidden_size)) - 1\n",
    "weights_1_2 = 2 * np.random.random((hidden_size, 1)) - 1\n",
    "\n",
    "# 2. PREDICT & COMPARE: Make a Prediction, Calculate Output & Delta\n",
    "layer_0 = lights[0:1]\n",
    "layer_1 = np.dot(layer_0, weights_0_1)\n",
    "layer_1 = relu(layer_1)\n",
    "layer_2 = np.dot(layer_1, weights_1_2)\n",
    "\n",
    "error = (layer_2 - walk_stop[0:1])**2\n",
    "layer_2_delta = (layer_2 - walk_stop[0:1])\n",
    "\n",
    "# 3. Backpropagate from Layer2 to Layer1\n",
    "layer_1_delta = layer_2_delta.dot(weights_1_2.T) \n",
    "layer_1_delta *= relu2deriv(layer_1)\n",
    "\n",
    "# 4. Generate Weight Deltas and Update Weights\n",
    "weights_delta_1_2 = layer_1.T.dot(layer_2_delta)\n",
    "weights_delta_0_1 = layer_0.T.dot(layer_1_delta)\n",
    "\n",
    "weights_1_2 -= alpha * weights_delta_1_2\n",
    "weights_0_1 -= alpha * weights_delta_0_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [[ 0.63423116]]\n",
      "Error: [[ 0.35838408]]\n",
      "Error: [[ 0.08301831]]\n",
      "Error: [[ 0.00646705]]\n",
      "Error: [[ 0.00032927]]\n",
      "Error: [[  1.50556227e-05]]\n"
     ]
    }
   ],
   "source": [
    "# Here is a self sufficient program that should run\n",
    "# MEMORIZE AND KNOW THIS BY HEART!\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "def relu(x):\n",
    "    return (x > 0) * x\n",
    "\n",
    "def relu2deriv(x):\n",
    "    return x > 0\n",
    "\n",
    "streetlights = np.array([[1, 0, 1],\n",
    "                         [0, 1, 1],\n",
    "                         [0, 0, 1],\n",
    "                         [1, 1, 1]])\n",
    "\n",
    "walk_stop = np.array([[1, 1, 0, 0]]).T\n",
    "\n",
    "alpha = 0.2\n",
    "hidden_size = 4\n",
    "input_size = 3\n",
    "\n",
    "weights_0_1 = 2 * np.random.random((input_size, hidden_size)) - 1\n",
    "weights_1_2 = 2 * np.random.random((hidden_size, 1)) - 1\n",
    "\n",
    "for iteration in range(60):\n",
    "    layer_2_error = 0\n",
    "    for i in range(len(streetlights)):\n",
    "        layer_0 = streetlights[i:i+1]\n",
    "        layer_1 = np.dot(layer_0, weights_0_1)\n",
    "        layer_1 = relu(layer_1)\n",
    "        layer_2 = np.dot(layer_1, weights_1_2)\n",
    "        \n",
    "        layer_2_error += (layer_2 - walk_stop[i:i+1])**2\n",
    "        layer_2_delta = layer_2 - walk_stop[i:i+1]\n",
    "        \n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T)\n",
    "        layer_1_delta *= relu2deriv(layer_1)\n",
    "        \n",
    "        weights_1_2_delta = layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1_delta = layer_0.T.dot(layer_1_delta)\n",
    "        \n",
    "        weights_1_2 -= weights_1_2_delta * alpha\n",
    "        weights_0_1 -= weights_0_1_delta * alpha\n",
    "        \n",
    "    if(iteration % 10 == 9):\n",
    "        print(\"Error: {}\".format(layer_2_error))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why do deep networks matter?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
